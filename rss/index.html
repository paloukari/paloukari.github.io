<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[HAVE DATA - WILL TRAIN]]></title><description><![CDATA[The adventures of a ML Engineer, who travels the Web working as a mercenary for people who hire him to solve their problems, but he provides his services for free to poor people that need his help]]></description><link>https://havedatawilltrain.com/</link><image><url>https://havedatawilltrain.com/favicon.png</url><title>HAVE DATA - WILL TRAIN</title><link>https://havedatawilltrain.com/</link></image><generator>Ghost 3.12</generator><lastBuildDate>Thu, 23 Apr 2020 02:37:46 GMT</lastBuildDate><atom:link href="https://havedatawilltrain.com/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Lysis]]></title><description><![CDATA[This is the ninth post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of the development experience with a custom emulated IoT Edge Runtime.]]></description><link>https://havedatawilltrain.com/lysis/</link><guid isPermaLink="false">5e9f74c4d47c36006e77105e</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Wed, 22 Apr 2020 23:29:26 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/bike-no-hands.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/bike-no-hands.jpg" alt="Lysis"><p>In the <a href="https://havedatawilltrain.com/genesis/">last post</a> we saw how to setup an F5 development experience for an IoT Edge application, without having to install the IoT Edge Runtime or any other tool on our localhost, but rather by mocking the runtime's behavior in one of our mock dependencies. In this post, we will see how to setup the same F5 experience, but with using the actual IoT Edge Runtime. </p><h3 id="emulating-iot-edge-runtime">Emulating IoT Edge Runtime Â </h3><p>Unfortunately, currently there is <strong>no development IoT Edge server</strong>, but we can build one!</p><blockquote>I have found that the effort of installing and troubleshooting the runtime exceeds the effort of building this custom emulator.</blockquote><p>To setup this development server, we will need to build a custom tool in C#.</p><p>Let's assume we would like to debug the <code>SimulatedTemperatureSensor</code> we built in the last post, but using the actual IoT Edge runtime this time instead of mocking it out. Let's create an new .NET Core console app next to the <code>SimulatedTemperatureSensor</code> that will hold all of our development tools:</p><pre><code class="language-bash">cd ..
mkdir DevelopmentTools
cd DevelopmentTools
dotnet new console
dotnet add package Microsoft.Azure.Devices
dotnet add package Docker.DotNet
code .</code></pre><p>This tool needs to perform three tasks:</p><ol><li>Provision a <strong>development IoT device.</strong></li><li>Create and push the appropriate <strong>development deployment manifest.</strong></li><li><strong>Run this device locally.</strong></li></ol><p>Here's the self-descriptive code of our tool's <code>Program.cs</code>:</p><pre><code class="language-csharp">namespace DevelopmenntTools
{
    using System;
    using System.IO;
    using System.Threading.Tasks;

    class Program
    {
        static async Task Main(string[] args)
        {
            if (args.Length != 3)
            {
                Console.WriteLine("Usage: dotnet run {MANIFEST_FILE} {DEVICE_ID} " +
                "{IOT_HUB_OWNER_COONECTION_STRING}");
                return;
            }
            var developmentManifest = Utilities.CreateDevelopmentManifest(
                File.ReadAllText(args[0]));

            var deviceConnectionString =
                await Utilities.ProvisionDeviceAsync(args[1],
                developmentManifest,
                args[2]);

            await Utilities.StartEmulatorAsync(deviceConnectionString);
        }
    }
}
</code></pre><p>We need to create a <code>Utilities.cs</code> file where we'll put the referenced three functions from above:</p><pre><code class="language-csharp">namespace DevelopmenntTools
{
    using Docker.DotNet;
    using Docker.DotNet.Models;
    using Microsoft.Azure.Devices;
    using Microsoft.Azure.Devices.Shared;
    using Newtonsoft.Json;
    using Newtonsoft.Json.Linq;
    using System;
    using System.Collections.Generic;
    using System.Linq;
    using System.Runtime.InteropServices;
    using System.Threading.Tasks;

    public static class Utilities
    {
        public static async Task StartEmulatorAsync(string deviceConnectionString)
        {
            string deviceContainerImage = "toolboc/azure-iot-edge-device-container";
            int[] exposedPorts = new[] { 15580, 15581, 443, 8883, 5671 };
            string imageName = "dev_iot_edge";

            var localDockerSocket = RuntimeInformation.IsOSPlatform(OSPlatform.Windows) ?
                @"npipe://./pipe/docker_engine" :
                @"unix:/var/run/docker.sock";

            var dockerClient = new DockerClientConfiguration(new Uri(localDockerSocket))
                .CreateClient();

            Console.WriteLine($"Downloading the latest image:{deviceContainerImage}..");

            await dockerClient.Images.CreateImageAsync(
                new ImagesCreateParameters
                {
                    FromImage = deviceContainerImage,
                    Tag = "latest"
                },
                new AuthConfig(),
                new Progress&lt;JSONMessage&gt;((e) =&gt;
                {
                    if (!string.IsNullOrEmpty(e.Status))
                        Console.Write($"{e.Status}");
                    if (!string.IsNullOrEmpty(e.Status))
                        Console.Write($"{e.ProgressMessage}");
                    if (!string.IsNullOrEmpty(e.Status))
                        Console.Write($"{e.ErrorMessage}");
                    Console.WriteLine("");
                }));

            var containers = await dockerClient.Containers
                .ListContainersAsync(new ContainersListParameters() { All = true });

            foreach (var _container in containers)
            {
                if (_container.Names.Contains(imageName) || 
                    _container.Names.Contains($@"/{imageName}"))
                {
                    if (_container.State == "running")
                    {
                        Console.WriteLine($"Stopping container {_container.ID}..");
                        await dockerClient.Containers.StopContainerAsync(_container.ID,
                            new ContainerStopParameters());
                    }
                    Console.WriteLine($"Removing container {_container.ID}..");
                    await dockerClient.Containers.RemoveContainerAsync(_container.ID,
                        new ContainerRemoveParameters());
                    break;
                }
            }

            Console.WriteLine($"Creating {imageName} container..");
            var container = await dockerClient.Containers
                .CreateContainerAsync(new CreateContainerParameters
            {
                AttachStderr = true,
                AttachStdin = true,
                AttachStdout = true,
                Tty = true,
                Env = new List&lt;string&gt;() { $"connectionString={deviceConnectionString}" },

                Name = imageName,
                Image = deviceContainerImage,
                ExposedPorts = exposedPorts
                    .ToDictionary(x =&gt; x.ToString(), x =&gt; default(EmptyStruct)),
                HostConfig = new HostConfig
                {
                    Privileged = true,
                    PortBindings = exposedPorts.ToDictionary(
                        x =&gt; x.ToString(),
                        x =&gt; (IList&lt;PortBinding&gt;)new List&lt;PortBinding&gt; {
                            new PortBinding {
                                HostPort = x.ToString()
                            }
                        }),
                    PublishAllPorts = true
                }
            });
            Console.WriteLine($"Starting {imageName} container..");
            var startResult = await dockerClient.Containers.StartContainerAsync(
                container.ID, null);

            if (!startResult)
                throw new Exception($"Cound not start the {imageName} container!");

            Console.WriteLine("Done.");
        }
        public static string CreateDevelopmentManifest(string template)
        {
            var templateContent = JsonConvert
                .DeserializeObject&lt;ConfigurationContent&gt;(template);
            
            var agentDesired = JObject.FromObject(
                   templateContent.ModulesContent["$edgeAgent"]["properties.desired"]);

            if (!agentDesired.TryGetValue("modules", out var modulesSection))
                throw new Exception("Cannot read modules config from $edgeAgent");

            foreach (var module in modulesSection as JObject)
            {
                var moduleSettings = JObject.FromObject(modulesSection[module.Key]["settings"]);
                moduleSettings["image"] = "wardsco/sleep:latest";
                modulesSection[module.Key]["settings"] = moduleSettings;
            }
            agentDesired["modules"] = modulesSection;
            templateContent.ModulesContent["$edgeAgent"]["properties.desired"]
                = agentDesired;


            return JsonConvert.SerializeObject(templateContent, Formatting.Indented,
                new JsonSerializerSettings
                {
                    NullValueHandling = NullValueHandling.Ignore
                });
        }
        public static async Task&lt;string&gt; ProvisionDeviceAsync(
            string deviceId,
            string manifest,
            string ioTHubConnectionString)
        {
            var registryManager = RegistryManager
                .CreateFromConnectionString(ioTHubConnectionString);

            var hostName = ioTHubConnectionString.Split(";")
                .SingleOrDefault(e =&gt; e.Contains("HostName="));

            if (string.IsNullOrEmpty(hostName))
                throw new ArgumentException(
                    $"Invalid ioTHubConnectionString: {ioTHubConnectionString}");
            hostName = hostName.Replace("HostName=", "");

            var device = await registryManager.GetDeviceAsync(deviceId) ??
                await registryManager.AddDeviceAsync(
                    new Device(deviceId)
                    {
                        Capabilities = new DeviceCapabilities() { IotEdge = true }
                    });

            var sasKey = device.Authentication.SymmetricKey.PrimaryKey;

            var manifestContent = JsonConvert
                .DeserializeObject&lt;ConfigurationContent&gt;(manifest);

            // remove all old modules
            foreach (var oldModule in await registryManager.GetModulesOnDeviceAsync(deviceId))
                if (!oldModule.Id.StartsWith("$"))
                    await registryManager.RemoveModuleAsync(oldModule);
            // create new modules
            foreach (var module in manifestContent.ModulesContent.Keys)
                if (!module.StartsWith("$"))
                    await registryManager.AddModuleAsync(new Module(deviceId, module));

            await registryManager
                .ApplyConfigurationContentOnDeviceAsync(deviceId, manifestContent);

            return $"HostName={hostName};DeviceId={deviceId};SharedAccessKey={sasKey}";
        }
    }
}
</code></pre><p>We need access to a running edge daemon and an edgeHub that our code will communicate with. This communication is secure, and because of that, we need first to create the <strong>module identity to use</strong>. To create this module identity, we simply need to describe a module in the deployment manifest.</p><p>Here are the contents of the application <code>manifest.json</code>:</p><blockquote>I prefer putting this file at the root directory level of the <strong>solution.</strong></blockquote><pre><code class="language-json">{
	"modulesContent": {
		"$edgeAgent": {
			"properties.desired": {
				"schemaVersion": "1.0",
				"runtime": {
					"type": "docker",
					"settings": {
						"minDockerVersion": "v1.25",
						"loggingOptions": "",
						"registryCredentials": {
						}
					}
				},
				"systemModules": {
					"edgeAgent": {
						"type": "docker",
						"settings": {
							"image": "mcr.microsoft.com/azureiotedge-agent:1.0.9",
							"createOptions": ""
						}
					},
					"edgeHub": {
						"type": "docker",
						"status": "running",
						"restartPolicy": "always",
						"settings": {
							"image": "mcr.microsoft.com/azureiotedge-hub:1.0.9",
							"createOptions": "{\"HostConfig\":{\"PortBindings\":{\"443/tcp\":[{\"HostPort\":\"443\"}],\"5671/tcp\":[{\"HostPort\":\"5671\"}],\"8883/tcp\":[{\"HostPort\":\"8883\"}]}}}"
						}
					}
				},
				"modules": {
					"SimulatedTemperatureSensor": {
						"version": "1.0",
						"type": "docker",
						"status": "running",
						"restartPolicy": "always",
						"settings": {
							"image": "your.azurecr.io/simulatedtemperaturesensor:latest",
							"createOptions": "{}"
						}
					}
				}
			}
		},
		"$edgeHub": {
			"properties.desired": {
				"schemaVersion": "1.0",
				"routes": {
					"allToIoTHub": "FROM /* INTO $upstream"
				},
				"storeAndForwardConfiguration": {
					"timeToLiveSecs": 10
				}
			}
		},
		"SimulatedTemperatureSensor": {
			"properties.desired": {
				"SendInterval": 1
			}
		}
	}
}</code></pre><blockquote>Note: we can modify this manifest to match our application requirements, for example, add more modules, define module twins, change the routes etc. The tool <strong>will simply replace the modules' container image with a mock container</strong>.</blockquote><p>Done! Let's run this console application passing the required arguments: </p><pre><code class="language-bash">dotnet run ../manifest.json dev_device "IOT HUB OWNER CONNECTION STRING"</code></pre><p>The effect of this execution is that we have <strong>a development IoT Edge device running in a local container</strong>, called <code>dev_iot_edge</code>. This container exposes the edge daemon and the edgeHub's ports to our host. All we have to do now us connect to it from our module.</p><p>To do that, we need to set some environment variables so that the IoT SDK can connect securely to the emulator. These variable have the prefix <code>IOTEDGE_</code> and we can get them from inside the running mock module of our emulator: </p><pre><code class="language-bash">docker exec dev_iot_edge bash -c "docker exec SimulatedTemperatureSensor env | grep IOTEDGE_"</code></pre><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/image-38.png" class="kg-image" alt="Lysis"></figure><p>We need to override the <code>IOTEDGE_GATEWAYHOSTNAME</code> with our host's name, and change the IP of the <code>IOTEDGE_WORKLOADURI</code> with <code>127.0.0.1</code>.</p><p>Setting these environment variables in our application will allow us to connect to the running emulator!</p><p>In practice, it's very easy to automate this process, with this helper function:</p><pre><code class="language-csharp">namespace SimulatedTemperatureSensor
{
    using System;
    using System.Diagnostics;
    using System.Linq;
    using System.Net;
    internal static class Utilities
    {
        internal static void InjectIoTEdgeVariables(string containerName)
        {
            var dockerCommand =
                $"docker exec dev_iot_edge bash -c \"docker exec {containerName} env | grep IOTEDGE_\"";
            Process p = new Process()
            {
                StartInfo = new ProcessStartInfo(dockerCommand)
                {
                    FileName = "cmd.exe",
                    Arguments = $"/C {dockerCommand}",
                    RedirectStandardError = true,
                    RedirectStandardOutput = true,
                    UseShellExecute = false,
                    CreateNoWindow = true
                },
            };
            p.Start();
            p.WaitForExit();

            var output = p.StandardOutput.ReadToEnd();
            var lines = output.Split(new[] { "\n" }, StringSplitOptions.None)
                .Where(e =&gt; e != null &amp;&amp; e.Contains("="));

            var variables = lines.ToDictionary(e =&gt; e.Split("=")[0], e =&gt; e.Split("=")[1]);

            // Overwrite these settigns
            variables["IOTEDGE_WORKLOADURI"] = "http://127.0.0.1:15581/";
            variables["IOTEDGE_GATEWAYHOSTNAME"] = Dns.GetHostName();
            foreach (var variable in variables)
            {
                Environment.SetEnvironmentVariable(variable.Key, variable.Value);
                Console.WriteLine($"Injected {variable.Key}={variable.Value}");
            }
        }
    }
}</code></pre><p> Then, when we're in the <code>Emulated</code> environment, we can automatically call this method from our application start up.</p><pre><code class="language-csharp">namespace SimulatedTemperatureSensor
{
    using System.Threading.Tasks;
    using Microsoft.Extensions.Configuration;
    using Microsoft.Extensions.DependencyInjection;
    using Microsoft.Extensions.Hosting;
    using Serilog;

    class Program
    {
        static async Task Main(string[] args)
        {
            using (var host = Host.CreateDefaultBuilder(args)
                 .ConfigureServices((hostContext, services) =&gt;
                 {
                     if (hostContext.HostingEnvironment.EnvironmentName == "Emulated")
                         Utilities.InjectIoTEdgeVariables("SimulatedTemperatureSensor");

                     services.AddSingleton&lt;IModuleClient, ModuleClientWrapper&gt;();
                     services.AddHostedService&lt;TemperatureSensorModule&gt;();
                 })
                 .UseSerilog((hostingContext, log) =&gt;
                 {
                     log.ReadFrom.Configuration(hostingContext.Configuration);
                 })
                 .UseConsoleLifetime()
                 .Build())
            {
                await host.RunAsync();
            }
        }
    }
}
</code></pre><blockquote>Note: you don't need to design your IoT Edge module project in the specific structure we used, <strong>even the monolithic C# template works with this approach</strong>. In fact, all supported programming languages will work!</blockquote><h3 id="module-container">Module Container </h3><p>After completing out implementation and testing, we need to build the module container image. This is easily done, both in VS Code and Visual Studio.</p><p>In Visual Studio:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="https://havedatawilltrain.com/content/images/2020/04/VSDocker.gif" class="kg-image" alt="Lysis"></figure><p>In VS Code:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="https://havedatawilltrain.com/content/images/2020/04/VSCodeDocker.gif" class="kg-image" alt="Lysis"></figure><p>Both tools will automatically populate the required Dockerfile, and will setup the <strong>build and run</strong> tasks. Simply hit <code>CTRL+SHIFT+B</code> to trigger the image build.</p><blockquote>You can even debug the same application running inside a Linux container! This is very useful when we have system dependencies that we cannot install on our host. </blockquote><p>Last step is to push this container to your container registry and update the manifest accordingly (currently set to <code>your.azurecr.io</code> ) </p><blockquote>You need to include the container registry credentials if any. </blockquote><p>The entire application is published in <a href="https://github.com/paloukari/SimulatedTemperatureSensor">this GitHub repo</a>.</p><h3 id="recap">Recap</h3><p>We saw how to setup an F5 development experience without using any tools, but just Docker and our C# code. This approach allows us to keep the same favorite development environment of our preference, without making any compromises.</p>]]></content:encoded></item><item><title><![CDATA[Genesis]]></title><description><![CDATA[This is the eight post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of the development experience with a mocked runtime.]]></description><link>https://havedatawilltrain.com/genesis/</link><guid isPermaLink="false">5e9dd9c7d47c36006e770c3f</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Wed, 22 Apr 2020 23:29:14 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/genesis.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/genesis.jpg" alt="Genesis"><p>In this blog post mini-series we have been exploring the gradual evolution of an IoT Edge application, starting from a tightly-coupled monolithic approach based on the default C# module template, to a more loosely coupled and composable application. In this post we will see how we can use this design to setup a true F5 development experience.</p><p>In the process of evolving our IoT Edge the application, we explored many best practices on various trivial IoT Edge topics, like controlling the application lifetime, logging, configuration, telemetry pumps and more. Now we will use an IoT Edge application example to see how all these things come together with setting up a flexible development environment. Although no prior knowledge is required to follow through, to get a better understanding of the design decisions, a review of the the pervious posts is highly recommended.</p><h2 id="improving-the-cli-based-current-development-experience">Improving the CLI-based current development experience</h2><p>In the past years we've witnessed the re-emergence of the CLI-oriented development, where people use various CLIs to compose, compile, containerize and publish their IoT Edge application. As an effect of this, today we can find a CLI for every <a href="https://docs.microsoft.com/en-us/cli/azure/azure-cli-extensions-list?view=azure-cli-latest">single thing</a>. And although these CLIs were meant to replace opinionated and platform-specific IDEs, like Visual Studio, these CLIs ended up getting integrated with development tools like VS Code, hidden behind their UI. </p><p>Specifically for the Azure IoT Edge development experience, the result has been disappointing, and for anyone who wants to build an IoT Edge application with beyond the <em>Hello World</em> level complexity, a better approach is required. In the following example, we will take a code-first approach: we will include most of the development tooling inside the application source code, so that people can get started with just cloning a repo.</p><h3 id="simulated-temperature-sensor-v2-0">Simulated Temperature Sensor v2.0</h3><p>Let's say we want to build from scratch the runtime's <a href="https://github.com/Azure/iotedge/tree/master/edge-modules/SimulatedTemperatureSensor">simulated temperature sensor</a> example, <strong>without any prior setup</strong>, starting from a clean Linux, macOS or Windows installation; I prefer using Visual Studio on Windows.</p><ol><li><a href="https://docs.microsoft.com/en-us/dotnet/core/install/sdk?pivots=os-linux">Install the latest .NET Core SDK</a>.</li><li>Install the <a href="https://code.visualstudio.com/download">latest VS Code</a>. </li><li>Create a folder: <br><code>mkdir SimulatedTemperatureSensor</code></li><li>Create a new console app in this folder: <br><code>cd SimulatedTemperatureSensor</code><br><code>dotnet new console</code></li><li>Install the following packages: <br><code>dotnet add package Microsoft.Azure.Devices.Client</code> <br><code>dotnet add package Microsoft.Extensions.Hosting</code> <br><code>dotnet add package Serilog.Extensions.Hosting</code> <br><code>dotnet add package Serilog.Settings.Configuration</code><br><code>dotnet add package Serilog.Sinks.Console</code><br><code>dotnet add package Serilog.Enrichers.Thread</code></li><li>Open the project in VS Code: <br><code>code .</code></li><li>Replace the Program.cs with the following code: </li></ol><pre><code class="language-csharp">namespace SimulatedTemperatureSensor
{
    using System.Threading.Tasks;
    using Microsoft.Extensions.DependencyInjection;
    using Microsoft.Extensions.Hosting;
    using Serilog;

    class Program
    {
        static async Task Main(string[] args)
        {
            using (var host = Host.CreateDefaultBuilder(args)
                .ConfigureServices((hostContext, services) =&gt;
                {
                    if(hostContext.HostingEnvironment.EnvironmentName == "Development")
                        services.AddSingleton&lt;IModuleClient, MockModuleClientWrapper&gt;();
                    else
                        services.AddSingleton&lt;IModuleClient, ModuleClientWrapper&gt;();

                    services.AddHostedService&lt;TemperatureSensorModule&gt;();
                })
                .UseSerilog((hostingContext, log) =&gt;
                {
                    log.ReadFrom.Configuration(hostingContext.Configuration);
                })
                .UseConsoleLifetime()
                .Build())
            {
                await host.RunAsync();
            }
        }
    }
}
</code></pre><blockquote>Note that we switch from <code>ModuleClientWrapper</code> to <code>MockModuleClientWrapper</code> when in development. This is controlled by the environment variable with name <code>DOTNET_ENVIRONMENT</code>.</blockquote><p>We've seen this code in the previous post, and in the one before that, we saw how to define an abstraction interface for the SDK's <code>ModuleClient</code> so that we can use it in a DI setup. Next, we will add this <code>IModuleClient</code> interface and the two <code>ModuleClientWrapper</code> and <code>MockModuleClientWrapper</code> classes:</p><pre><code class="language-csharp">namespace SimulatedTemperatureSensor
{
    using System.Threading;
    using System.Threading.Tasks;
    using Microsoft.Azure.Devices.Shared;
    using Microsoft.Azure.Devices.Client;
    
    public interface IModuleClient
    {
        Task OpenAsync(CancellationToken cancellationToken);
        Task CloseAsync(CancellationToken cancellationToken);
        Task SendEventAsync(string outputName,
            Message message);
        Task SetInputMessageHandlerAsync(string inputName,
            MessageHandler messageHandler,
            object userContext);
        Task SetMethodHandlerAsync(string methodName,
            MethodCallback methodHandler,
            object userContext);
        Task&lt;Twin&gt; GetTwinAsync(CancellationToken cancellationToken);
        Task&lt;Twin&gt; GetTwinAsync();
    }
}</code></pre><p>and the class <code>ModuleClientWrapper</code>:</p><pre><code class="language-csharp">namespace SimulatedTemperatureSensor
{
    using Microsoft.Azure.Devices.Client;
    using Microsoft.Azure.Devices.Client.Transport.Mqtt;
    using Microsoft.Azure.Devices.Shared;
    using Microsoft.Extensions.Configuration;
    using Microsoft.Extensions.Logging;
    using System.Threading;
    using System.Threading.Tasks;

    public class ModuleClientWrapper : IModuleClient
    {
        readonly ModuleClient moduleClient;
        readonly ILogger logger;

        public ModuleClientWrapper(IConfiguration configuration,
            ILogger&lt;ModuleClientWrapper&gt; logger)
        {
            this.logger = logger;

            var transportType = 
                configuration.GetValue("ClientTransportType", TransportType.Amqp_Tcp_Only);

            ITransportSettings[] settings = { new MqttTransportSettings(transportType) };

            moduleClient = ModuleClient.CreateFromEnvironmentAsync(settings).Result;
        }

        public async Task SendEventAsync(string outputName, Message message)
        {
            await moduleClient.SendEventAsync(outputName, message);
        }

        public async Task SetInputMessageHandlerAsync(string inputName,
            MessageHandler messageHandler,
            object userContext)
        {
            await moduleClient.SetInputMessageHandlerAsync(inputName,
                messageHandler,
                userContext);
        }

        public async Task SetMethodHandlerAsync(string methodName,
            MethodCallback methodHandler,
            object userContext)
        {
            await moduleClient.SetMethodHandlerAsync(methodName,
                methodHandler,
                userContext);
        }
        public async Task OpenAsync(CancellationToken cancellationToken)
        {
            await moduleClient.OpenAsync(cancellationToken);
        }
        public async Task CloseAsync(CancellationToken cancellationToken)
        {
            await moduleClient.CloseAsync(cancellationToken);
        }
        public async Task&lt;Twin&gt; GetTwinAsync(CancellationToken cancellationToken)
        {
            return await moduleClient.GetTwinAsync(cancellationToken);
        }
        public async Task&lt;Twin&gt; GetTwinAsync()
        {
            return await moduleClient.GetTwinAsync();
        }
    }
}</code></pre><p>And finally here's a mock implementation of the above class. The purpose of this class is to simulate the IoT Edge Runtime behavior for development and testing purposes.</p><pre><code class="language-csharp">namespace SimulatedTemperatureSensor
{
    using System;
    using System.Collections.Generic;
    using System.Threading;
    using System.Threading.Tasks;
    using Microsoft.Azure.Devices.Client;
    using Microsoft.Azure.Devices.Shared;
    using Microsoft.Extensions.Hosting;
    using Microsoft.Extensions.Logging;

    internal class MockModuleClientWrapper : IModuleClient
    {
        readonly ILogger logger;
        readonly IHostApplicationLifetime application;

        readonly TaskTimer taskTimer;
        readonly Dictionary&lt;string, List&lt;Message&gt;&gt; messageQueues;
        readonly Dictionary&lt;string, ValueTuple&lt;MessageHandler, object&gt;&gt; inputMessageHandlers;
        readonly Dictionary&lt;string, MethodCallback&gt; methodMessageHandlers;

        public MockModuleClientWrapper(IHostApplicationLifetime application,
            ILogger&lt;MockModuleClientWrapper&gt; logger)
        {
            this.logger = logger;
            this.application = application;

            messageQueues = new Dictionary&lt;string, List&lt;Message&gt;&gt;();
            inputMessageHandlers = new Dictionary&lt;string, (MessageHandler, object)&gt;();
            methodMessageHandlers = new Dictionary&lt;string, MethodCallback&gt;();

            taskTimer = new TaskTimer(OnTimer, TimeSpan.FromSeconds(1), logger);
        }

        private void OnTimer()
        {
            lock (messageQueues)
                foreach (var queue in messageQueues)
                {
                    if (inputMessageHandlers.ContainsKey(queue.Key))
                        foreach (var message in queue.Value)
                            inputMessageHandlers[queue.Key].Item1(message, inputMessageHandlers[queue.Key].Item2);
                    messageQueues[queue.Key].Clear();
                }
            // TODO: Process method messsages too
        }

        public Task SendEventAsync(string outputName, Message message)
        {
            lock (messageQueues)
            {
                if (!messageQueues.ContainsKey(outputName))
                    messageQueues[outputName] = new List&lt;Message&gt;();
                messageQueues[outputName].Add(message);
            }
            logger.LogInformation($"Message Sent to {outputName}");
            return Task.CompletedTask;
        }

        public Task SetInputMessageHandlerAsync(string inputName, MessageHandler messageHandler, object userContext)
        {
            inputMessageHandlers[inputName] = (messageHandler, userContext);
            logger.LogInformation($"Message Handler Set for {inputName}");
            return Task.CompletedTask;
        }

        public Task SetMethodHandlerAsync(string methodName, MethodCallback methodHandler, object userContext)
        {
            methodMessageHandlers[methodName] = methodHandler;
            logger.LogInformation($"Method Handler Set for {methodName}");
            return Task.CompletedTask;
        }

        public Task OpenAsync(CancellationToken token)
        {
            logger.LogInformation("Opened ModuleClient");
            taskTimer.Start(application.ApplicationStopping);
            return Task.CompletedTask;
        }

        public Task CloseAsync(CancellationToken token)
        {
            logger.LogInformation("Closed ModuleClient");
            return Task.CompletedTask;
        }

        public Task&lt;Twin&gt; GetTwinAsync(CancellationToken cancellationToken)
        {
            logger.LogInformation("GetTwinAsync");
            return Task.FromResult&lt;Twin&gt;(null);
        }

        public Task&lt;Twin&gt; GetTwinAsync()
        {
            logger.LogInformation("GetTwinAsync");
            return Task.FromResult&lt;Twin&gt;(null);
        }
    }
}</code></pre><p>We have almost everything in place. The last missing piece is to implement the <code>TemperatureSensorModule</code> class, the class that will contain the <em>business logic </em>of our IoT Edge application. This module will periodically emit messages, simulating a temperature sensor. </p><p>Following the same approach we did <a href="https://havedatawilltrain.com/the-man-who-wouldnt-test/">last time</a>, this class will implement the <code>IHostedService</code>. We will include an <code>IHostApplicationLifetime</code> dependency to gain control on the application lifetime and trigger a restart in case something goes terribly wrong. Finally, we'll use an updated version of the <a href="https://havedatawilltrain.com/the-waiting-loop/"><code>TaskTimer</code></a> we saw in a <a href="https://havedatawilltrain.com/the-waiting-loop/">previous post</a> to drive the telemetry loop:</p><p>Here's the <code>TaskTimer</code> class:</p><pre><code class="language-csharp">namespace SimulatedTemperatureSensor
{
    using System;
    using System.Threading;
    using System.Threading.Tasks;
    using Microsoft.Extensions.Logging;

    public class TaskTimer
    {
        readonly Action onTimer;
        readonly TimeSpan timerPeriod;
        readonly Action onError;
        readonly ILogger logger;

        public TaskTimer(Action onTimer,
            TimeSpan timerPeriod,
            ILogger logger,
            Action onError = null)
        {
            this.timerPeriod = timerPeriod;
            this.onTimer = onTimer;
            this.logger = logger;
            this.onError = onError;
        }

        public void Start(CancellationToken token)
        {
            Task elapsedTask = null;
            elapsedTask = new Task((x) =&gt;
            {
                OnTimer(elapsedTask, token);
            }, token);

            HandleError(elapsedTask, token);

            elapsedTask.Start();
        }

        private void OnTimer(Task task, object objParam)
        {
            var start = DateTime.Now;
            var token = (CancellationToken)objParam;

            if (token.IsCancellationRequested)
            {
                logger.LogInformation("A cancellation has been requested.");
                return;
            }

            onTimer();

            var delay = timerPeriod - (DateTime.Now - start);
            if (delay.Ticks &gt; 0)
            {
                task = Task.Delay(delay);
            }
            HandleError(task.ContinueWith(OnTimer, token), token);
        }

        private void HandleError(Task task, CancellationToken token)
        {
            task.ContinueWith((e) =&gt;
            {
                logger.LogError(
                    $"Exception when running timer callback: {e.Exception}");

                onError?.Invoke();
                if (!token.IsCancellationRequested)
                    task.ContinueWith(OnTimer, token);

            }, TaskContinuationOptions.OnlyOnFaulted);
        }
    }
}</code></pre><p>Here's the code of the <code>TemperatureSensorModule</code>:</p><pre><code class="language-csharp">
namespace SimulatedTemperatureSensor
{
    using Microsoft.Azure.Devices.Client;
    using Microsoft.Extensions.Configuration;
    using Microsoft.Extensions.Hosting;
    using Microsoft.Extensions.Logging;
    using System;
    using System.Text;
    using System.Threading;
    using System.Threading.Tasks;

    public class TemperatureSensorModule : IHostedService
    {
        const string SAMPLING_PERIOD_CONFIG_NAME = "TelemetryPeriodSeconds";
        const int SAMPLING_PERIOD_DEFAULT = 1;
        
        readonly IModuleClient moduleClient;
        readonly ILogger logger;
        readonly IHostApplicationLifetime application;
        
        readonly Random random = new Random();
        readonly TaskTimer telemetryPump;

        public TemperatureSensorModule(IModuleClient moduleClient,
            IConfiguration config,
            IHostApplicationLifetime application, 
            ILogger&lt;TemperatureSensorModule&gt; logger)
        {
            this.moduleClient = moduleClient;
            this.logger = logger;
            this.application = application;

            var period = TimeSpan.FromSeconds(
                config.GetValue(SAMPLING_PERIOD_CONFIG_NAME, SAMPLING_PERIOD_DEFAULT));

            telemetryPump = new TaskTimer(OnTimer, period, logger, application.StopApplication);
            
            application.ApplicationStopping.Register(() =&gt;
            {
                logger.LogWarning("Stop-draining application for 3 seconds...");
                Task.Delay(TimeSpan.FromSeconds(3)).Wait();
            });
        }

        private async void OnTimer()
        {
            await moduleClient.SendEventAsync("telemetry",
                new Message(Encoding.UTF8.GetBytes($"Current temperature: {random.Next(0, 100)}")));
        }

        public async Task StartAsync(CancellationToken cancellationToken)
        {
            await moduleClient.OpenAsync(cancellationToken);
            telemetryPump.Start(application.ApplicationStopping);

            logger.LogInformation("Started.");
        }

        public async Task StopAsync(CancellationToken cancellationToken)
        {
            await moduleClient.CloseAsync(cancellationToken);
            logger.LogInformation("Stopped.");
        }
    }
}
</code></pre><p>This is the project <code>appSettings.json</code> content that contains just our Serilog config:</p><pre><code class="language-json">{
  "Serilog": {
    "Using": [ "Serilog.Sinks.Console" ],
    "MinimumLevel": {
      "Default": "Debug"
    },
    "WriteTo": [
      {
        "Name": "Console",
        "Args": {
          "outputTemplate": "{Timestamp:yyyy-MM-dd HH:mm:ss.fff zzz} [{Level:u3}] [{SourceContext}] [{ThreadId}] - {Message}{NewLine}{Exception}"
        }
      }
    ],
    "Enrich": [ "FromLogContext", "WithThreadId" ]
  }
}</code></pre><p>This the project file structure so far:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/image-35.png" class="kg-image" alt="Genesis"></figure><p>Our first version is ready. Set the <code>DOTNET_ENVIRONMENT</code> environment variable to <code>Development</code> and hit F5 to run the application. Hit <code>CTRL+C</code> to gracefully stop it.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="https://havedatawilltrain.com/content/images/2020/04/dev-ex-large.gif" class="kg-image" alt="Genesis"></figure><h3 id="recap">Recap</h3><p>Following this approach, we are allowing ourselves to <strong>develop most the Edge application as a console app, </strong>using the most easy F5 development experience, without any prior setup.</p><p><a href="https://havedatawilltrain.com/lysis/">Next</a>, we will see how we can gradually transform this standalone development environment to becoming our Azure IoT Edge development environment, without sacrificing any flexibility once so ever! </p>]]></content:encoded></item><item><title><![CDATA[The Man Who Wouldn't Test]]></title><description><![CDATA[This is the seventh post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of dependency injection.]]></description><link>https://havedatawilltrain.com/the-man-who-wouldnt-test/</link><guid isPermaLink="false">5e98d5add47c36006e770848</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Sat, 18 Apr 2020 00:28:49 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/pussel_dusk_closeup.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/pussel_dusk_closeup.jpg" alt="The Man Who Wouldn't Test"><p>In the <a href="https://havedatawilltrain.com/the-reasonable-man/">last post</a> we refactored the <strong>default Azure IoT Edge Module C# template code </strong>with a couple of dependency abstractions. In this post we will add a dependency injection mechanism in the mix and we will evolve this application example to a level that can be a good starting point for every Azure IoT Edge application.</p><p>In the final version of the <code>Program.cs</code> of the <a href="https://havedatawilltrain.com/the-reasonable-man/">previous post</a>, we reached a point where we could <strong>compose </strong>the dependencies together and create a <em>business </em>instance of the <code>PipeModule</code>. A simplified summarization of this composition is:</p><pre><code class="language-csharp">IConfiguration configuration = new ConfigurationBuilder()
    .AddJsonFile("appsettings.json", optional: true)
    .AddEnvironmentVariables()
    .AddCommandLine(args)
    .Build();

var cancellationTokenSource = new CancellationTokenSource();

IModuleClient moduleClient = new ModuleClientWrapper();

IDatabaseClient databaseClient = 
	new DatabaseClientWrapper(configuration);

PipeModule pipeModule = new PipeModule(moduleClient, databaseClient);</code></pre><p>In this dependency hierarchy, we had to explicitly pass the previously created instances to create more complex ones, all the way to creating the <code>PipeModule</code>. Although this approach is far better than the monolithic approach of the original template code, <strong>we still have hardcoded dependencies</strong>: to replace a dependency, we would still need to change this code, recompile and redeploy.</p><p>Wouldn't be nice if there was a mechanism that satisfied this hierarchy dependency composition dynamically, so that we can drive our changes via the configuration?</p><p>The <code>Microsoft.Extensions.Hosting</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting?view=dotnet-plat-ext-3.1">namespace</a> contains many utility classes like the <code><a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.hostbuilder?view=dotnet-plat-ext-3.1">HostBuilder</a></code>. This library is a good starting point because it references all other required libraries like the <code>Microsoft.Extensions.Configuration</code>, <code>Microsoft.Extension.DependencyInjection</code> and <code>Microsoft.Extension.Logging</code> and brings together all these abstractions and functionality under a few simple interfaces.</p><blockquote>Note: to install this extension library, run:<br><code>dotnet add package Microsoft.Extensions.Hosting</code> </blockquote><p>In contrast to the Azure IoT SDK, this library excels in <strong>distinguishing the application from the host</strong>. The <code>HostBuilder</code> is a very useful utility that helps us to compose together our <strong>application services</strong> and our hosting <strong>infrastructure</strong>. A service is a component of our application, an element in our application dependency hierarchy, and the hosting <strong>infrastructure</strong> is anything specific to the hosting environment, like for example the environment variables configuration.</p><p>Let's now refactor our previous example by using the <code>HostBuilder</code> to configure our dependencies. We'll start first by implementing the <code>IHostedService</code> interface in our <code>PipeModule</code> class. This interface defines just two methods:</p><pre><code class="language-csharp">public interface IHostedService
{
    Task StartAsync(CancellationToken cancellationToken);
    Task StopAsync(CancellationToken cancellationToken);
}</code></pre><p>And yes, the <code>PipeModule</code> from the last post already implements these two methods, so we should just add this interface in the class signature:</p><pre><code class="language-csharp">public class PipeModule : IHostedService</code></pre><p>Now, we can replace the entire <code>Program</code> class with this code:</p><pre><code class="language-csharp">class Program
{
    static async Task Main(string[] args)
    {
        // Read the configuration
        IConfiguration configuration = new ConfigurationBuilder()
                .AddJsonFile("appsettings.json", optional: true)
                .AddEnvironmentVariables()
                .AddCommandLine(args)
                .Build();

        // Create the cancelation token source
        var cancellationTokenSource = new CancellationTokenSource();

        // Register to the application lifetime events
        AssemblyLoadContext.Default.Unloading +=
        (cts) =&gt; cancellationTokenSource.Cancel();

        Console.CancelKeyPress +=
            (sender, cts) =&gt;
            {
                Console.WriteLine("Ctrl+C detected.");
                cts.Cancel = true;
                cancellationTokenSource.Cancel();
            };

        // Build the host
        using (var host = new HostBuilder()
            .ConfigureServices((hostContext, services) =&gt;
            {
                services.AddSingleton(cancellationTokenSource);
                services.AddSingleton&lt;IModuleClient, ModuleClientWrapper&gt;();
                services.AddSingleton&lt;IDatabaseClient, DatabaseClientWrapper&gt;();
                services.AddHostedService&lt;PipeModule&gt;();
            })
            .Build())
        {

            // Start the application
            host.Start();

            // Wait until the app unloads or is cancelled
            await WhenCancelled(cancellationTokenSource.Token);
        }

    }
    public static Task WhenCancelled(CancellationToken cancellationToken)
    {
        var taskCompletionSource = new TaskCompletionSource&lt;bool&gt;();
        cancellationToken.Register(
            s =&gt; ((TaskCompletionSource&lt;bool&gt;)s).SetResult(true),
            taskCompletionSource);
        return taskCompletionSource.Task;
    }
}</code></pre><blockquote>Note: the <code>AddSingleton</code> is used when we want to add a service that will be unique for the entire application. Singletons become the classes that carry <strong>state </strong>or <strong>identity</strong>, like the <code>cancellationTokenSource</code> and <code>IModuleClient</code> respectively.</blockquote><blockquote>Note: the <code>AddHostedService</code> is used for services that need to be started by the host.</blockquote><p>We already saw how to control the application lifetime with the <code>CancellationTokenSource</code> in <a href="https://havedatawilltrain.com/restarted-by-request/">this post</a>. The truth is that in the early versions of .NET Core, the <code>AppDomain.CurrentDomain.ProcessExit</code> event was replaced by the <code>AssemblyLoadContext.Default.Unloading</code> event, but now both of them exist and can be used interchangeably.</p><p>In the <code>IHostBuilder</code> we can find the <code>UseConsoleLifetime()</code> extension method, which simply adds an <code><a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostlifetime?view=dotnet-plat-ext-3.1">IHostLifetime</a></code> service which is suitable for console apps, the <code>Microsoft.Extensions.Hosting.Internal.ConsoleLifetime</code> service. <strong>The <code><a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostlifetime?view=dotnet-plat-ext-3.1">IHostLifetime</a></code> services control when the host starts and when it stops</strong>.</p><p>This <code>ConsoleLifetime</code> service:</p><ul><li>Listens for <code>Ctrl+C</code>/ <code>SIGINT</code> or <code>SIGTERM</code> and calls <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostapplicationlifetime.stopapplication"><code>StopApplication</code></a> to start the shutdown process.</li><li>Unblocks extensions such as <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1#runasync"><code>RunAsync</code></a> and <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1#waitforshutdownasync"><code>WaitForShutdownAsync</code></a>.</li></ul><p>Let's refactor the above code now using this lifecycle service:</p><pre><code class="language-csharp">class Program
{
    static async Task Main(string[] args)
    {
        // Read the configuration
        IConfiguration configuration = new ConfigurationBuilder()
                .AddJsonFile("appsettings.json", optional: true)
                .AddEnvironmentVariables()
                .AddCommandLine(args)
                .Build();

        // Build the host
        using (var host = new HostBuilder()
            .ConfigureServices((hostContext, services) =&gt;
            {
                services.AddSingleton&lt;IModuleClient, ModuleClientWrapper&gt;();
                services.AddSingleton&lt;IDatabaseClient, DatabaseClientWrapper&gt;();
                services.AddHostedService&lt;PipeModule&gt;();
            })
            .UseConsoleLifetime()
            .Build())
        {
            // Run the application and wait for the application to exit
            await host.RunAsync();
        }
    }
}</code></pre><blockquote>What do you know! After seven posts, we're back to a single-page long <code>Main</code>! </blockquote><p>In the above version, instead of passing the <code>CancellationTokenSource</code> to our services to signal an application termination, we can inject the <code>IHostApplicationLifetime</code> service:</p><pre><code class="language-csharp">public DatabaseClientWrapper(IHostApplicationLifetime hostApplicationLifetime)</code></pre><p>Then, we can register to the <code>ApplicationStopping</code>event to gracefully stop the service, and call the <code>StopApplication()</code> to trigger an application termination from inside the service.</p><blockquote>A very good description of the startup and shutdown sequence can be found <a href="https://andrewlock.net/introducing-ihostlifetime-and-untangling-the-generic-host-startup-interactions/">here</a> Â </blockquote><p>We've also <a href="https://havedatawilltrain.com/the-service-room/">analyzed</a> the difference between the <strong>application </strong>and the <strong>system configuration</strong>,<strong> </strong>and we examined a few best practices on managing this configuration. Similarly to the <code>UseConsoleLifetime()</code> extension, the <code>ConfigureHostConfiguration</code> and <code>ConfigureAppConfiguration</code> extension methods are there to help us read the application and the host configuration. </p><p>Let's see how this looks like:</p><pre><code class="language-csharp">class Program
{
    static async Task Main(string[] args)
    {
        // Build the host
        using (var host = new HostBuilder()
            .ConfigureHostConfiguration(configHost =&gt;
            {
                configHost.SetBasePath(Directory.GetCurrentDirectory());
                configHost.AddJsonFile("hostsettings.json", optional: true);
                configHost.AddEnvironmentVariables(prefix: "PREFIX_");
                configHost.AddCommandLine(args);
            })
            .ConfigureAppConfiguration((hostContext, configApp) =&gt;
            {
                configApp.AddJsonFile("appsettings.json", optional: true);
                configApp.AddJsonFile(
                    $"appsettings.{hostContext.HostingEnvironment.EnvironmentName}.json",
                    optional: true);
                configApp.AddEnvironmentVariables();
                configApp.AddCommandLine(args);
            })
            .ConfigureServices((hostContext, services) =&gt;
            {
                services.AddSingleton&lt;IModuleClient, ModuleClientWrapper&gt;();
                services.AddSingleton&lt;IDatabaseClient, DatabaseClientWrapper&gt;();
                services.AddHostedService&lt;PipeModule&gt;();
            })
            .UseConsoleLifetime()
            .Build())
        {
            // Run the application and wait for the application to exit
            await host.RunAsync();
        }
    }
}</code></pre><blockquote>Note that when we read the application configuration in the <code>ConfigureAppConfiguration</code>, we have access to the host configuration via the <code>hostContext.Configuration</code> property. </blockquote><p>The application configuration now will automatically be injected to any service that depends on it, like the <code>DatabaseClientWrapper</code> we implemented in the last post.</p><p>A final step is to configure and hook up our logging logic. One alternative is to use the corresponding extension method, like for example:</p><pre><code class="language-csharp">.ConfigureLogging((logging) =&gt;
{
    logging.AddFilter("Microsoft", LogLevel.Warning);
    logging.AddFilter("System", LogLevel.Warning);
    logging.AddFilter("DependencyInjection.Program", LogLevel.Debug);
    logging.AddConsole();
    logging.AddDebug();
    logging.AddEventSourceLogger();
    logging.AddEventLog();
})</code></pre><p>If we do this, we've just replicated the behavior of the <strong>.NET Generic Host, </strong>which is just a pre-defined host configuration, as described <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1#default-builder-settings">here</a>.</p><p>Then our code can be simplified to:</p><pre><code class="language-csharp">class Program
{
    static async Task Main(string[] args)
    {
        // Build default host
        using (var host = Host.CreateDefaultBuilder(args)
            .ConfigureServices((hostContext, services) =&gt;
            {
                services.AddSingleton&lt;IModuleClient, ModuleClientWrapper&gt;();
                services.AddSingleton&lt;IDatabaseClient, DatabaseClientWrapper&gt;();
                services.AddHostedService&lt;PipeModule&gt;();
            })
            .UseConsoleLifetime()
            .Build())
        {
            // Run the application and wait for the application to exit
            await host.RunAsync();
        }
    }
}</code></pre><p>Alternatively, we can use a <code>Serilog</code> logger, driven by configuration. To do this, we will add the <code>Serilog.Extensions.Hosting</code> nuget package:</p><pre><code class="language-csharp">class Program
{
    static async Task Main(string[] args)
    {
        // Build default host
        using (var host = Host.CreateDefaultBuilder(args)
            .ConfigureServices((hostContext, services) =&gt;
            {
                // Configure our services
                services.AddSingleton&lt;IModuleClient, ModuleClientWrapper&gt;();
                services.AddSingleton&lt;IDatabaseClient, DatabaseClientWrapper&gt;();
                services.AddHostedService&lt;PipeModule&gt;();
            })
            .UseSerilog((hostingContext, log) =&gt;
            {
                log.ReadFrom.Configuration(hostingContext.Configuration);
            })
            .UseConsoleLifetime()
            .Build())
        {
            // Run the application and wait for the application to exit
            await host.RunAsync();
        }
    }
}</code></pre><p>By doing so, we get the expected logger injection behavior by adding a logger dependency in a constructor:</p><pre><code class="language-csharp">public DatabaseClientWrapper(ILogger&lt;DatabaseClientWrapper&gt; logger)</code></pre><p>Also, the <code>Serilog.Log.Logger</code> is set implicitly, and can be accessed from everywhere by the static <code>Serilog.Log</code> property.</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/impressive.gif" class="kg-image" alt="The Man Who Wouldn't Test"></figure><p>It is impressive how much plumbing code is hidden in this last version, but without losing the ability to override the default host builder if we want to, as we did with the Serilog logger.</p><h3 id="recap">Recap</h3><p>In these mini-series blog posts we have explored various patterns and best practices and we managed to evolve the monolithic Azure IoT Edge module C# template code to a loosely coupled application that allows us have a true F5 development experience and define unit tests.</p><p>In the next post we will explore how we can use this loosely coupled design to setup our development environment.</p>]]></content:encoded></item><item><title><![CDATA[The Reasonable Man]]></title><description><![CDATA[This is the sixth post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of inversion of control and dependency injection.]]></description><link>https://havedatawilltrain.com/the-reasonable-man/</link><guid isPermaLink="false">5e95fe62e73bbc006e59f48e</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Thu, 16 Apr 2020 21:52:33 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/masks.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/masks.jpg" alt="The Reasonable Man"><p>So far, in this mini-series we have explored various approaches on some standard issues that every IoT Edge application needs to address. In this post we will start exploring the big picture, a complete example that is production-ready and that can act as a good starting point the Azure IoT Edge application developement.</p><p>In the previous posts <strong>we meticulously avoided introducing any technology-specific dependencies </strong>in our evolving thermostat application example, either by temporarily omitting the code, or by abstracting the various libraries' behavior behind predefined interfaces. The benefit of this is that we keep our business code <strong>technology-agnostic</strong>, and as such, we can easily test it. We have also preserved the freedom to switch platforms any time we choose to. Let's see how we can get there.</p><p>But first..</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/image-33.png" class="kg-image" alt="The Reasonable Man"></figure><h2 id="the-azure-iot-module-template">The Azure IoT Module Template</h2><p>Let's use an example to make this easier to understand. Let's assume that we want to implement an Azure IoT Edge module, <strong>starting from the default <a href="https://github.com/Azure/dotnet-template-azure-iot-edge-module">Azure IoT Edge Module</a> template</strong>. This template is a simple .NET Core console app, with all the required IoT SDK references in it, that simply echoes all messages coming from the input <code>input1</code> to the output <code>output1</code>. Let's assume we'd like extend this template by <strong>recording every message in a database</strong>. </p><blockquote>The original template source code is <a href="https://github.com/Azure/dotnet-template-azure-iot-edge-module/blob/master/content/dotnet-template-azure-iot-edge-module/CSharp/Program.cs">here</a>.</blockquote><p>This is a modified version that includes the message database recording:</p><pre><code class="language-csharp">namespace DependencyInjection
{
    using System;
    using System.IO;
    using System.Runtime.InteropServices;
    using System.Runtime.Loader;
    using System.Security.Cryptography.X509Certificates;
    using System.Text;
    using System.Threading;
    using System.Threading.Tasks;
    using Microsoft.Azure.Amqp.Framing;
    using Microsoft.Azure.Devices.Client;
    using Microsoft.Azure.Devices.Client.Transport.Mqtt;

    class Program
    {
        static int counter;
        static void Main(string[] args)
        {
            Init().Wait();

            // Wait until the app unloads or is cancelled
            var cts = new CancellationTokenSource();
            AssemblyLoadContext.Default.Unloading += (ctx) =&gt; cts.Cancel();
            Console.CancelKeyPress += (sender, cpe) =&gt; cts.Cancel();
            WhenCancelled(cts.Token).Wait();
        }

        /// &lt;summary&gt;
        /// Handles cleanup operations when app is cancelled or unloads
        /// &lt;/summary&gt;
        public static Task WhenCancelled(CancellationToken cancellationToken)
        {
            var tcs = new TaskCompletionSource&lt;bool&gt;();
            cancellationToken.Register(s =&gt; ((TaskCompletionSource&lt;bool&gt;)s).SetResult(true), tcs);
            return tcs.Task;
        }

        /// &lt;summary&gt;
        /// Initializes the ModuleClient and sets up the callback to receive
        /// messages containing temperature information
        /// &lt;/summary&gt;
        static async Task Init()
        {
            MqttTransportSettings mqttSetting = new MqttTransportSettings(TransportType.Mqtt_Tcp_Only);
            ITransportSettings[] settings = { mqttSetting };

            // Open a connection to the Edge runtime
            ModuleClient ioTHubModuleClient = await ModuleClient.CreateFromEnvironmentAsync(settings);
            await ioTHubModuleClient.OpenAsync();
            Console.WriteLine("IoT Hub module client initialized.");

            // Initialize the database client
            var connectionString = Environment.GetEnvironmentVariable("DbConnectionString");
            DatabaseClient databaseClient = DatabaseClient.CreateFromConnectionString(connectionString);

            // Register callback to be called when a message is received by the module
            await ioTHubModuleClient.SetInputMessageHandlerAsync("input1", PipeMessage, (ioTHubModuleClient, databaseClient));
        }

        /// &lt;summary&gt;
        /// This method is called whenever the module is sent a message from the EdgeHub. 
        /// It just pipe the messages without any change.
        /// It prints all the incoming messages.
        /// &lt;/summary&gt;
        static async Task&lt;MessageResponse&gt; PipeMessage(Message message, object userContext)
        {
            int counterValue = Interlocked.Increment(ref counter);

            var (moduleClient, databaseClient) = ((ModuleClient, DatabaseClient))userContext;
            

            byte[] messageBytes = message.GetBytes();
            string messageString = Encoding.UTF8.GetString(messageBytes);
            Console.WriteLine($"Received message: {counterValue}, Body: [{messageString}]");

            if (!string.IsNullOrEmpty(messageString))
            {
                using (var pipeMessage = new Message(messageBytes))
                {
                    foreach (var prop in message.Properties)
                    {
                        pipeMessage.Properties.Add(prop.Key, prop.Value);
                    }
                    
                    await databaseClient.RecordMessageAsync(pipeMessage);
                    
                    await moduleClient.SendEventAsync("output1", pipeMessage);

                    Console.WriteLine("Received message sent");
                }
            }
            return MessageResponse.Completed;
        }
    }
}
</code></pre><p>We've made just <strong>a few small changes</strong> to the original template code:</p><ol><li>Inside the <code>Init()</code> we now create our <code>DatabaseClient</code> instance:</li></ol><pre><code class="language-csharp">// Initialize the database client
var connectionString = Environment.GetEnvironmentVariable("DbConnectionString");
DatabaseClient databaseClient = DatabaseClient.CreateFromConnectionString(connectionString);</code></pre><p>2. Inside the <code>PipeMessage</code> we get the <code>databaseClient</code> instance from the method <code>userContext</code> with:</p><pre><code class="language-csharp">var (moduleClient, databaseClient) = ((ModuleClient, DatabaseClient))userContext;</code></pre><p> 3. In the same <code>PipeMessage</code> we record the message with: </p><pre><code class="language-csharp">await databaseClient.RecordMessageAsync(pipeMessage);</code></pre><p>This is clearly a monolithic and tightly-coupled implementation. <strong>This code will fail </strong>if we don't have a valid connection string and the required environment variables to create the <code>ModuleClient</code>. Even if we did have the required environment variables, we would still need a running database and the entire IoT Edge Device Runtime in place to get it working. </p><p>So, the only way to test this <code>PipeMessage</code> code is </p><ul><li>to setup an IoT Edge Device on your development environment</li><li>setup a database server on your development environment</li><li>build and deploy a new version of the edge application </li><li>either attach a debugger to the running container or start searching through the logs. </li></ul><p>This apparently leaves unit testing out of the question.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/back2theFuture.gif" class="kg-image" alt="The Reasonable Man"><figcaption>Welcome to 1985!</figcaption></figure><p>Congrats! You just traveled 35 years back in the software!</p><h2 id="inversion-of-control"><strong>Inversion of Control</strong></h2><p>In it's simplest form, dependency injection is an abstraction strategy that allows us to decouple our business code from any technical implementation. The idea is fairly simple: for every dependency, we define an interface that describes well the dependency's public behavior. Then, for each module we define the it's dependencies at the constructor, by adding the dependency interface as constructor arguments. </p><blockquote><strong>A dependency is something that we use but we don't control</strong>, eg. the <code>ModuleClient</code> and the <code>DatabaseClient</code>, because their behavior <strong>depends </strong>on external processes.</blockquote><p>Let's define these two abstractions. We'll start with the <code>DatabaseClient</code> class. </p><blockquote>For the purpose of simplicity, this is an imaginary database SDK.</blockquote><p>We start by defining a simple interface that contains all useful behavior:</p><pre><code class="language-csharp">public interface IDatabaseClient
{
    Task OpenAsync(CancellationToken cancellationToken);
    Task CloseAsync(CancellationToken cancellationToken);
    Task RecordMessageAsync(byte[] message);
}</code></pre><p>Then, we define a wrapper class that implements this interface and wraps the original <code>DatabaseClient</code> object:</p><pre><code class="language-csharp">internal class DatabaseClientWrapper : IDatabaseClient
{
    const string CONNECTION_STRING_NAME = "dbConnectionString";
    DatabaseClient _databaseClient { get; }

    public DatabaseClientWrapper(IConfiguration configuration)
    {
        var connectionString =
            configuration.GetConnectionString(CONNECTION_STRING_NAME);

        _databaseClient = DatabaseClient.
                CreateFromConnectionString(connectionString);
    }
    public async Task OpenAsync(CancellationToken cancellationToken)
    {
        await _databaseClient.OpenAsync(cancellationToken);
    }

    public async Task CloseAsync(CancellationToken cancellationToken)
    {
        await _databaseClient.CloseAsync(cancellationToken);
    }

    public async Task RecordMessageAsync(byte[] message)
    {
        await _databaseClient.RecordMessageAsync(message);
    }
}</code></pre><blockquote>Note: this wrapper class "depends" on <code>IConfiguration</code></blockquote><p>What have we achieved? We can now replace the <code>DatabaseClient</code> references with <code>IDatabaseClient</code>, which means we don't have any more hardcoded references on this database SDK inside <code>Program.cs</code>.</p><p>Let's do the same for the <code>ModuleClient</code>. A first version of the interface can be:</p><pre><code class="language-csharp">public interface IModuleClient
{
    Task OpenAsync(CancellationToken cancellationToken);
    Task CloseAsync(CancellationToken cancellationToken);
    Task SendEventAsync(string outputName, 
        Message message);
    Task SetInputMessageHandlerAsync(string inputName, 
        MessageHandler messageHandler, 
        object userContext);
    Task SetMethodHandlerAsync(string methodName, 
        MethodCallback methodHandler, 
        object userContext);
    Task&lt;Twin&gt; GetTwinAsync(CancellationToken cancellationToken);
    Task&lt;Twin&gt; GetTwinAsync();
}</code></pre><p>and the wrapper class can be:</p><pre><code class="language-csharp">public class ModuleClientWrapper : IModuleClient
{
    private ModuleClient ModuleClient { get; }

    public ModuleClientWrapper()
    {
        MqttTransportSettings mqttSetting = 
                new MqttTransportSettings(TransportType.Mqtt_Tcp_Only);
        ITransportSettings[] settings = { mqttSetting };

        ModuleClient = ModuleClient.CreateFromEnvironmentAsync(settings).Result;
    }

    public async Task SendEventAsync(string outputName, Message message)
    {
        await ModuleClient.SendEventAsync(outputName, message);
    }

    public async Task SetInputMessageHandlerAsync(string inputName, 
        MessageHandler messageHandler, 
        object userContext)
    {
        await ModuleClient.SetInputMessageHandlerAsync(inputName, 
            messageHandler, 
            userContext);
    }

    public async Task SetMethodHandlerAsync(string methodName, 
        MethodCallback methodHandler, 
        object userContext)
    {
        await ModuleClient.SetMethodHandlerAsync(methodName, 
            methodHandler, 
            userContext);
    }
    public async Task OpenAsync(CancellationToken cancellationToken)
    {
        await ModuleClient.OpenAsync(cancellationToken);
    }
    public async Task CloseAsync(CancellationToken cancellationToken)
    {
        await ModuleClient.CloseAsync(cancellationToken);
    }
    public async Task&lt;Twin&gt; GetTwinAsync(CancellationToken cancellationToken)
    {
        return await ModuleClient.GetTwinAsync(cancellationToken);
    }
    public async Task&lt;Twin&gt; GetTwinAsync()
    {
        return await ModuleClient.GetTwinAsync();
    }
}</code></pre><p>After abstracting our dependencies, the final step is to isolate our <em>business</em> code in a new class that <strong><em>depends </em>on these two interfaces. </strong></p><p>Let's call this class <code>PipeModule</code>:</p><pre><code class="language-csharp">public class PipeModule
{
    IModuleClient _moduleClient { get; }
    IDatabaseClient _databaseClient { get; }
    public PipeModule(IModuleClient moduleClient, 
        IDatabaseClient databaseClient)
    {
        _moduleClient = moduleClient;
        _databaseClient = databaseClient;
    }
    public async Task StartAsync(CancellationToken cancellationToken)
    {
        await _moduleClient.OpenAsync(cancellationToken);
        await _databaseClient.OpenAsync(cancellationToken);

        await _moduleClient.SetInputMessageHandlerAsync("input1",
            new MessageHandler(async (message, context) =&gt;
            {
                await _databaseClient.RecordMessageAsync(message.GetBytes());
                await _moduleClient.SendEventAsync("output1", message);
                return await Task.FromResult(MessageResponse.Completed);
            }), this);
    }
        
    public async Task StopAsync(CancellationToken cancellationToken)
    {
        await _moduleClient.CloseAsync(cancellationToken);
        await _databaseClient.CloseAsync(cancellationToken);
    }
}</code></pre><p>This class contains some initialization and termination logic, and our piping <em>business </em>code, which is just these two lines:</p><pre><code class="language-csharp">await _databaseClient.RecordMessageAsync(message.GetBytes());
await _moduleClient.SendEventAsync("output1", message);</code></pre><p>Now, with these abstractions in mind, let's see what the original example looks like:</p><pre><code class="language-csharp">class Program2
{
    static async Task Main(string[] args)
    {
        // Read the configuration
        IConfiguration configuration = new ConfigurationBuilder()
                .AddJsonFile("appsettings.json", optional: true)
                .AddEnvironmentVariables()
                .AddCommandLine(args)
                .Build();

        // Create the cancelation token source
        var cancellationTokenSource = new CancellationTokenSource();
        AssemblyLoadContext.Default.Unloading +=
            (cts) =&gt; cancellationTokenSource.Cancel();

        Console.CancelKeyPress +=
            (sender, cts) =&gt;
            {
                Console.WriteLine("Ctrl+C detected.");
                cts.Cancel = true;
                cancellationTokenSource.Cancel();
            };

        await Init(configuration, cancellationTokenSource.Token);

        // Wait until the app unloads or is cancelled
        await WhenCancelled(cancellationTokenSource.Token);
    }
    public static Task WhenCancelled(CancellationToken cancellationToken)
    {
        var taskCompletionSource = new TaskCompletionSource&lt;bool&gt;();
        cancellationToken.Register(
            s =&gt; ((TaskCompletionSource&lt;bool&gt;)s).SetResult(true),
            taskCompletionSource);
        return taskCompletionSource.Task;
    }
    static async Task Init(IConfiguration configuration, 
        CancellationToken cancellationToken)
    {
        IModuleClient moduleClient = new ModuleClientWrapper();
        IDatabaseClient databaseClient = 
                new DatabaseClientWrapper(configuration);

        await moduleClient.OpenAsync(cancellationToken);
        await databaseClient.OpenAsync(cancellationToken);
        
        PipeModule pipeModule = new PipeModule(moduleClient, 
            databaseClient);
        await pipeModule.StartAsync(cancellationToken);

        Console.WriteLine("Module initialized.");
    }
}</code></pre><p>Besides the <code>PipeModule</code>, this version includes some of the best practices from the previous posts. Although the code is much simpler, this is just an interim version, we still have a few missing things to take care of, namely, the dependency injection mechanism. </p><p>In the next post we will include a dependency injection mechanism that is based on the <code>Microsoft.Extensions.Hosting</code> library and we will see the benefits of doing so.</p>]]></content:encoded></item><item><title><![CDATA[The Log Hunt]]></title><description><![CDATA[This is the fifth post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of the application logging.]]></description><link>https://havedatawilltrain.com/the-log-hunt/</link><guid isPermaLink="false">5e9086adca768b2661b5cbb7</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Tue, 14 Apr 2020 16:06:18 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/linearB-1.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/linearB-1.jpg" alt="The Log Hunt"><p>In the <a href="https://havedatawilltrain.com/the-service-room/">last post</a>, we touched on the topic of the application logging. We talked about the need for separation of the configuration information into two distinct categories: application and systemic. To emphasize this, we used one of the archetypical tasks in software engineering, the <strong>diagnostic information</strong> extraction in a debugging environment. </p><p>In this post we will explore in depth the best practices of application logging and extend it in the broader IoT space.</p><h2 id="sources-and-sinks">Sources and Sinks</h2><p>Historically, the various logging libraries have been inspired by the hosting operating system underlying implementation. The reason for this is somewhat obvious if seen from the perspective of the hardware (device): the operating system itself is just a collection of applications, some of them running on the kernel space like drivers, and some in the user space, like any user application. In mission-critical applications, the related logging information might span a cross-section of OS components, drivers and other applications, so having a consolidated logging mechanism makes more sense.</p><p>And although minor differences existed between the different operating systems' logging infrastructure, all of them shared the same <strong>publisher/subscriber </strong>pattern: the log stream is published by <strong>sources</strong>, and <strong>sinks </strong>can subscribe to these sources. Â On Windows, the inherent logging infrastructure is called <strong>ETW</strong> and on Linux <strong>LTTng</strong>, both of them the de facto best approach for platform-specific tracing.</p><p>Nowadays, in the era of cloud computing, anything that is platform-specific sounds like a bad idea, and rightfully so, people try to avoid it. Logging in the Â .NET ecosystem has traditionally been confusing, with many alternatives and no clear winner so far. But at last, we have a clear winner! Today, <strong><a href="https://serilog.net/">Serilog</a></strong> is the second most popular nuget package right after Newtonsoft's JSON library. This practically means that the most important logging features are supported, and even if there is any missing feature or limitation in this library compared to other options, it's most probably a matter of time for the Serilog open source community to catch-up. As of now, most of the important tracing sinks exist, like for example flat files, databases, cloud managed tracing services etc. </p><p>Now let's see how this looks in source code. Let's modify the default .NET Core console app to use Serilog. To create a new Console app in .NET Core run:</p><pre><code class="language-shell">mkdir Logging
dotnet new console

dotnet add package Microsoft.Extensions.Hosting

dotnet add package Serilog.Sinks.Console
dotnet add package Serilog.Settings.Configuration
dotnet add package Serilog.Enrichers.Thread</code></pre><p>Replace the default <code>Program.cs</code> code with this:</p><pre><code class="language-csharp">using Microsoft.Extensions.Configuration;
using Serilog;
using Serilog.Context;

namespace Logging
{
    class Program
    {
        static void Main(string[] args)
        {
            IConfiguration configuration = new ConfigurationBuilder()
                .AddJsonFile("appsettings.json")
                .Build();

            Log.Logger = new LoggerConfiguration()
                .ReadFrom.Configuration(configuration)
                .CreateLogger();

            LogContext.PushProperty("ClassId", typeof(Program).Name);
            LogContext.PushProperty("FunctionId", nameof(Main));

            Log.Information("Hello World!");
            Log.Error("Something is wrong..");
            Log.Information("Goodbye!");
        }
    }
}
</code></pre><p>and add this <code>appsettings.json</code> file and set it to "copy if newer"</p><pre><code class="language-json">{
  "Serilog": {
    "Using": [ "Serilog.Sinks.Console" ],
    "MinimumLevel": {
      "Default": "Debug"
    },
    "WriteTo": [
      {
        "Name": "Console",
        "Args": {
          "outputTemplate": "{Timestamp:yyyy-MM-dd HH:mm:ss.fff zzz} [{Level:u3}] [{ModuleId}] [{ThreadId}] - {Message}{NewLine}{Exception}"
        }
      }
    ],
    "Enrich": [ "FromLogContext", "WithThreadId" ]
  }
}</code></pre><blockquote>Note: In VSCode you can copy to output the <code>appsettings.json</code> by adding this snippet in the <code>.csproj</code> file: </blockquote><pre><code class="language-xml">  &lt;ItemGroup&gt;
    &lt;None Update="appsettings.json"&gt;
      &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
    &lt;/None&gt;
  &lt;/ItemGroup&gt;
</code></pre><p>Running this application, we see the following output:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/image-30.png" class="kg-image" alt="The Log Hunt"></figure><p>A few important notes about the above example:</p><ol><li>We put the Serilog settings in the <code>appsettings.json</code> file. A better approach would be to to have a <strong>dedicated file</strong>, just for the purpose of logging.</li><li>More elaborate log event <a href="https://github.com/serilog/serilog/wiki/Enrichment">enrichment</a> alternatives exist, removing or adding more information to each log event is a matter of preference (and performance).</li><li>We set the static <code>Log.Logger</code> property with the new logger. This way we can access the logger by simply doing <code>Log.Information</code>. This simple approach works well only if we have need a single logger instance in our entire application. </li></ol><h3 id="the-canonical-example">The canonical example </h3><p>For a better control over the logger creation, a good<strong> logger example </strong>exists in the IoT Edge runtime <a href="https://github.com/Azure/iotedge/blob/master/edge-util/src/Microsoft.Azure.Devices.Edge.Util/Logger.cs">source code</a>. This example demonstrates a good way to remove the the Serilog specific implementation dependency from the rest of the source code by implementing the and the <code><a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.logging.iloggerfactory?view=dotnet-plat-ext-3.1">ILoggerFactory</a></code> interface of the <code>Microsoft.Extensions.Logging</code> namespace and hiding the Serilog specific references behind this implementation.</p><p>A usage example of the above approach, using a slightly modified version of the aforementioned logger of the IoT Edge Runtime looks like:</p><pre><code class="language-csharp">using Microsoft.Extensions.Logging;

namespace Logging
{
    class Program1
    {
        static readonly ILogger Log = 
            Logger.Factory.CreateLogger(typeof(Program).Name);

        static void Main(string[] args)
        {
            Log.LogInformation("Hello World!");
            Log.LogError("Something is wrong..");
            Log.LogInformation("Goodbye!");
        }
    }
}
</code></pre><blockquote>Note that there is no reference to the Serilog namespace anymore. The benefit of this is that we've made our code technology-agnostic, that is, we can replace the logging library by simply changing our Logger class implementation.</blockquote><p>Running the above code produces a similar output</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/image-31.png" class="kg-image" alt="The Log Hunt"></figure><p>Besides the output logs style, the major difference between these two examples is that now we can pass this logger to third party libraries that use the same logging abstraction. This is a subtle difference, but it can prove to be very helpful in various scenarios, integrating with ASP.NET Core. </p><blockquote>Note: we will see how this becomes important in the next post where we introduce dependency injection </blockquote><h2 id="docker-and-azure-iot-edge">Docker and Azure IoT Edge </h2><p>So far, the focus has been intentionally limited in generating application logs and sending them to a console sink. Obviously, <a href="https://github.com/serilog/serilog/wiki/Provided-Sinks">many other</a> sink options exist, some of them pushing the logs in remote cloud sinks like Azure Event Hubs or Blob Storage. The console sink approach works well both in development environments and when deploying as a container, because Docker can be configured to save these logs in host flat files and then combine these logs on a system level with other OS logs.</p><p>The related IoT manifest section is:</p><pre><code class="language-json">"createOptions": {
    "HostConfig": {
        "LogConfig": {
            "Type": "json-file",
            "Config": {
                "max-size": "10m",
                "max-file": "3"
            }
        }
    }
}</code></pre><blockquote>Note: by default the Moby container engine does not set container log size limits!</blockquote><p>Finally, a couple of notable Azure IoT Edge log features are the <a href="https://github.com/Azure/iotedge/blob/master/doc/built-in-logs-pull.md">log collation and upload capability</a> and the <a href="https://github.com/veyalla/logspout-loganalytics">Azure Log Analytics integration module</a>. </p><p>To summarize the logging story, the rules of thumb are:</p><ol><li>Use Serilog library for logging. If you configure Serilog via configuration, use a dedicated file. Write to at least a console sink.</li><li>Reference and use the <code>Serilog.Log</code> if your code is relatively simple and does not integrate with other external libraries.</li><li>Implement an <code>ILoggerFactory</code> and use dependency injection if you have integration with external libraries, like ASP.NET Core.</li><li>Set a limit to the docker logs.</li><li>Never push logs in the same application payload transport channel, use a dedicated transport channel if you push your logs to the upstream.</li><li>If your Edge application is part of a broader distributed solution, use the Application Insights sink and correlation IDs.</li><li>For ad hoc log retrieval use the <a href="https://github.com/Azure/iotedge/blob/master/doc/built-in-logs-pull.md">log collation and upload capability</a>.</li><li>For continuous push edge log, use the <a href="https://github.com/veyalla/logspout-loganalytics">Azure Log Analytics integration module</a>.</li><li>Configure the OS with a host management solution to retrieve the system logs.</li></ol><p>In the next post, we will explore a dependency injection approach that combines all concepts we've seen so far in this mini-series .</p>]]></content:encoded></item><item><title><![CDATA[The Service Room]]></title><description><![CDATA[This is the fourth post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of the application configuration.]]></description><link>https://havedatawilltrain.com/the-service-room/</link><guid isPermaLink="false">5e8ba7eaca768b2661b5c8d7</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Fri, 10 Apr 2020 18:38:20 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/willys-jeep-dashboard-marco-oliveira.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/willys-jeep-dashboard-marco-oliveira.jpg" alt="The Service Room"><p>Reading <strong>configuration settings </strong>is one of the most fundamental tasks of any IoT Edge application. We will postulate a configuration categorization and explore how this categorization maps to .NET. Although these examples are specific to Azure IoT Edge applications, the best practices presented here are generic and apply to all other application types. Â </p><h2 id="application-configuration">Application Configuration</h2><h3></h3><p>A well-designed application needs to be able to adjust its behavior based on the <strong>environment </strong>it is running in. And although the definition of the environment can become a matter of debate, there are some commonly accepted standard environments in Software Engineering: <strong>Development</strong>, <strong>Test</strong>, <strong>Staging</strong> and <strong>Production</strong>. Apparently, some variability exists to the cardinality of these environments, sometimes merging together some of them (eg. Test and Staging), and similarly, an environment can split into more specialized cases.</p><p>In reality, besides the environments related to the application lifecycle, an environment can be defined arbitrarily: can be based on geographical location, on physical characteristics, like ambient temperature or water pH, business parameters, like if an item has been sold or not, etc. This diversity of all possible environments makes the environment modeling difficult. Â </p><p>To shed some light, we'll draw an example from real life, something that almost all people can relate to, <strong>cars. </strong></p><blockquote>Cars can be one of the best analogy examples one can find, mostly because cars are complex machines that most people have interacted with. Cars carry many well-designed features that many software engineers draw inspiration from when designing things.</blockquote><h3 id="environments">Environments</h3><p>Most modern ECUs (the main computer of a car) are designed to behave differently when in maintenance mode, when the service mechanic plugs in the diagnostic tool. This can be seen as analogous to a Debugging environment, where the TCU architects made sure that the TCU will emit diagnostic information to help the mechanic understand if there are any issues with the car. These environments are called <strong>lifecycle environments</strong>. </p><p>A second category of an environment is the <strong>operating environment, </strong>the environment in which a car is driven in. Many SUVs allow the drivers to choose between 4x4 and rear wheel drive based on the operating environment traction requirements. Similarly, the vehicle A/C can be turned on and off, according to the environment conditions. You can either define explicitly the environment, via a push button, or infer the environment by reading the sensors; for example infer that it's currently raining by reading the rain sensor. Many of these environment-based decisions have been automated today: the vehicle lights will turn on when it's dark, the A/C will kick-in when it's hot etc. Nevertheless, the point here is that the vehicle designers made the car <strong>real-time configurable </strong>to conform to the operating environment conditions.</p><blockquote><u>If seen from this standpoint, <strong>the application configuration is effectively information that defines an environment!</strong></u></blockquote><h3 id="device-twin">Device Twin</h3><p>The long intro and the emphasis to the application configuration definition is necessary, because having a clear understanding of what the configuration information is and what is not, affects the abstraction decisions we make that down the line become the difference between a well-designed and a poorly-designed application. </p><p>The notion of a <strong>device twin </strong>exists in the IoT space.<strong> </strong>Specifically, in Azure IoT Edge, the <a href="https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-device-twins">definition</a> of the device twin is: "<em><u>Device twins</u></em><u> are JSON documents that store device state information including metadata, </u><strong><u>configurations</u></strong><u>, and conditions</u>". The device twin is practically a collection of name-value properties that fall into the two self-explanatory categories, the <strong>desired </strong>and the <strong>reported </strong>properties.</p><p>Let's go back to the car example. Congrats! You just got hired by an automotive company to write the TCU software of their new <strong>connected vehicle car model</strong>. Would you store any lifecycle environment information in the device twin? How about the operating environment information, like for example, if it's is currently raining?</p><p>The lines can get easily blurred between the device state, the device configuration conditions and metadata. Â Using the car analogy, we can draw a clear line to separate the configuration in two major categories:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/Auto-mechanic-using-laptop_24096043_s-Custom.jpg" class="kg-image" alt="The Service Room"><figcaption>System configuration</figcaption></figure><ul><li><strong>System (device) configuration</strong>, the configuration that the mechanic (administrator) can change, for example, set the engine idle RPM. The system configuration maps to the <strong>lifecycle environment definition. </strong>These environments are related to the lifecycle of the vehicle, are clearly defined and changing them usually requires an expert, tools and a vehicle restart.</li></ul><p></p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/image-22.png" class="kg-image" alt="The Service Room"><figcaption>User configuration</figcaption></figure><ul><li><strong>User configuration</strong>, the configuration that the vehicle drivers (users) can change, for example, the steering wheel height or the radio station. This is easier to achieve through a user interface. The user configuration maps to the <strong>operation environment definition</strong>. This environment can change dynamically, no restart is required and the vehicle driver (user) has the power to define it.</li></ul><blockquote>Note: In IoT, there's always an administrator, and the devices that do not interact with users, don't have user configuration.</blockquote><p>By using these definitions, the rest of the story around configuration falls into place: </p><ol><li>The system configuration is kept into the system itself, and <strong>to change the system configuration, a restart is required, perhaps even a new deployment.</strong> The system configuration is enforced, the device either conforms, or fails to start. </li><li>On the other hand, the <strong>user configuration is persisted in the desired properties</strong> of the digital twin. These can change on the fly, and perhaps by external systems, and the device should try to do its best to honor these updates, although this configuration can be seen more like hints.</li><li>Finally, all the <strong>read-only sensory values are the reported properties</strong> of the device twin.</li></ol><blockquote>Food for thought: Where would you store the default values of the user configuration?</blockquote><p>Let's see now how all these look written in source code.</p><h3 id="reading-system-configuration">Reading System Configuration</h3><p>For system configuration we'll use the following Â packages:</p><ul><li><code>Microsoft.Extensions.Configuration</code> </li><li><code>Microsoft.Extensions.Configuration.Abstractions</code></li><li><code>Microsoft.Extensions.Configuration.CommandLine</code></li><li><code>Microsoft.Extensions.Configuration.EnvironmentVariables</code></li><li><code>Microsoft.Extensions.Configuration.Json</code></li></ul><p>Using these packages we can write a simple application that reads the system information:</p><figure class="kg-card kg-code-card"><pre><code class="language-csharp">using System;
using System.Threading.Tasks;
using Microsoft.Extensions.Configuration;

namespace Example5
{
    class Program
    {
        // This is the program entry point
        static async Task Main(string[] args)
        {
            // Read the system configuration
            IConfiguration configuration;
            configuration = new ConfigurationBuilder()
                .AddJsonFile("appsettings.json", optional: true)
                .AddEnvironmentVariables()
                .AddCommandLine(args)
                .Build();

            if (configuration["Environment"] == "Debug")
            {
                Console.WriteLine($"Configuring for debugging environment..");
                // Code omitted
            }
            Console.WriteLine("Exiting..");
        }
    }
}</code></pre><figcaption>Reading the System Configuration using <code>Microsoft.Extensions.Configuration</code></figcaption></figure><p>The <code>IConfiguration</code> property will hold the configuration settings <strong>union</strong>, based on the order of composition we define. In this example, we start with an optional local JSON file <code>appsettings.json</code>, then we add the environment variables and the command line arguments. Each time we add a new configuration source, we override any variables with the same name.</p><blockquote>A good practice is to keep the hosting environment configuration last. This allows us change the configuration without redeploying a new file system version.</blockquote><p>Running this application with command line arguments makes easier to test our code:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/config.gif" class="kg-image" alt="The Service Room"></figure><h3 id="writing-system-configuration">Writing System Configuration </h3><p>To set this configuration, you can either push an updated <code>appsettings.json</code> file through a new deployment, or set the <code>settings.createOptions.Env</code> section of a module in the deployment manifest:</p><pre><code class="language-json">          "module2": {
            ...
            "settings": {
              "createOptions": {
                "Env": [
                  "DB_SERVER_URL=${DB_SERVER_URL}"
                ]
              }
            }
          }</code></pre><h3 id="reading-user-configuration">Reading User Configuration</h3><p>To read the user configuration from the device twin, we can use this code snippet:</p><figure class="kg-card kg-code-card"><pre><code class="language-csharp">await ModuleClient.OpenAsync();
var twin = await ModuleClient.GetTwinAsync();
if (twin!= null &amp;&amp; twin.Properties.Desired.Contains("IntervalInSeconds"))
	int.TryParse(twin.Properties.Desired["IntervalInSeconds"], out IntervalInSeconds);</code></pre><figcaption>Reading user configuration from the device twin&nbsp;</figcaption></figure><h3 id="writing-user-configuration">Writing User Configuration Â </h3><p>You have two options to update the user configuration: via <a href="https://docs.microsoft.com/en-us/azure/iot-edge/module-composition#define-or-update-desired-properties">deployment manifest </a>or by using the service-side IoT SDK.</p><p>The deployment manifest has the <code>properties.desired</code> section per module. Setting this section requires a redeployment and an application restart. You can think this section as the default values of the module twin.</p><pre><code class="language-json">        "module1": {
            "properties.desired": {
                // desired properties of module1
            }
        },</code></pre><p>Conversely, you can set the module twin using the Service (cloud) side of the Azure IoT SDK. A complete example can be found <a href="https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-csharp-csharp-module-twin-getstarted">here</a>.</p><p>To better understand the different categories and their corresponding location throughout the system, we can visualize everything in a single diagram:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/image-27.png" class="kg-image" alt="The Service Room"></figure><h3 id="the-thermostat-example">The Thermostat Example</h3><p>Revisiting the original thermostat example we saw in the <a href="https://havedatawilltrain.com/the-waiting-loop/">previous post</a>, now the thermostat code looks like:</p><pre><code class="language-csharp">using System;
using System.Runtime.Loader;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Configuration;

namespace Example6
{
    class Program
    {
        // This is the program entry point
        static async Task Main(string[] args)
        {
            // Read the system configuration
            IConfiguration configuration;
            configuration = new ConfigurationBuilder()
                .AddJsonFile("appsettings.json", optional: true)
                .AddEnvironmentVariables()
                .AddCommandLine(args)
                .Build();

            // Create the cancelation token source
            var cancellationTokenSource = new CancellationTokenSource();
            AssemblyLoadContext.Default.Unloading +=
                (cts) =&gt; cancellationTokenSource.Cancel();

            Console.CancelKeyPress +=
                (sender, cts) =&gt;
                {
                    Console.WriteLine("Ctrl+C detected.");
                    cts.Cancel = true;
                    cancellationTokenSource.Cancel();
                };

            // Register the Reset command callback 
            await RegisterCommandCallbackAsync("Reset",
                OnReset,
                cancellationTokenSource.Token);

            // Read the system configuration or default to 1
            int interval;
            if (!int.TryParse(
                configuration["IntervalInSeconds"],
                out interval))
                interval = 1;

            // Create and start the TaskTimer
            TaskTimer taskTimer = new TaskTimer(
                EmitTelemetryMessage,
                TimeSpan.FromSeconds(interval), 
                cancellationTokenSource);

            // A non-blocking call to start the task-timer
            taskTimer.Start();

            // Wait until the app unloads or gets cancelled
            await WhenCancelled(cancellationTokenSource.Token);

            // Let the other threads drain
            Console.WriteLine("Waiting for 2 seconds..");
            await Task.Delay(2 * 1000);

            Console.WriteLine("Exiting..");
        }

        public static Task WhenCancelled(CancellationToken cancellationToken)
        {
            var taskCompletionSource = new TaskCompletionSource&lt;bool&gt;();
            cancellationToken.Register(
                s =&gt; ((TaskCompletionSource&lt;bool&gt;)s).SetResult(true),
                taskCompletionSource);
            return taskCompletionSource.Task;
        }
        private static async Task RegisterCommandCallbackAsync(string command,
            Action callback,
            CancellationToken cancellationToken)
        {
            // Perform the command registration
            // Code omitted
            return;
        }

        // A method exposed for RPC
        static void OnReset()
        {
            // Perform a temperature sensor reset
            // Code omitted
        }

        // Emit telemetry message
        static void EmitTelemetryMessage()
        {
            Console.WriteLine($"Sending telemetry message..");
        }
    }
}
</code></pre><blockquote>So far in this mini-series we have deliberately avoided using the Azure IoT SDK, the idea being, we want to build a <strong>hosting environment agnostic </strong>application, were the code is not coupled to a specific hosting technology. With this approach, hosting it on the Edge becomes a choice, and helps us to develop most of the code in our preferred development environment.</blockquote><p>As alluded to this post, one of the most popular cases for reconfiguring the IoT application is for debugging purposes. In the next post we will explore the best practices on application logging.</p>]]></content:encoded></item><item><title><![CDATA[The Waiting Loop]]></title><description><![CDATA[This is the third post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of the telemetry pump.]]></description><link>https://havedatawilltrain.com/the-waiting-loop/</link><guid isPermaLink="false">5e860b6b188f260074a3084e</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Sat, 04 Apr 2020 00:48:28 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/penguins-1.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/penguins-1.jpg" alt="The Waiting Loop"><p>In IoT, a very common coding pattern is having an endless loop that does some periodic work and emits telemetry based on the work result. In the example we saw in the <a href="https://havedatawilltrain.com/restarted-by-request/">previous post</a>, we used the <code>EmitTelemetryMessagesAsync</code> to simulate a temperature sensor, but in real life, this function would read the value of an actual hardware temperature sensor and send out the temperature telemetry event. From now on, we will call this pattern <strong>telemetry pump.</strong></p><p>The telemetry pump pattern is very old. In fact, every Windows application has a similar pump, but for UI events instead of telemetry events. This pump is the dispatching mechanism of the OS events to your application. Similarly in the IoT context, a telemetry pump acts as the dispatching interface between the hardware sensors and the cloud.</p><h2 id="publisher-subscriber">Publisher/Subscriber </h2><p>In an ideal world, a publisher/subscriber pattern that is based on hardware interrupts would be a more elegant approach. Nevertheless, <strong>the hardware world is full of uncertainty: </strong>originating in Heisenberg's uncertainty principle, there is always some degree of noise when we try to measure any physical phenomenon. This means that consecutive measurement values will jitter (try measuring voltage with a high-accuracy voltmeter). For this reason, most of the times we're forced to use <strong>periodical polling </strong>instead of change-driven updates. And depending on the required data resolution, we can come up with the <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">required minimum frequency</a>.</p><h2 id="timers">Timers </h2><p>Many telemetry pumps designs exist, depending on the depth of the technology stack we're working on. The periodical nature of the sensor polling often inspires people to use <a href="https://docs.microsoft.com/en-us/windows/win32/sync/using-timer-queues">timers</a>. Although timers may seem conceptually a suitable and easy approach, timers usually get you in trouble. <u>There is no guarantee that the previous iteration has completed before the timer fires again</u>. Indeed, if for example we're emitting a telemetry message every second, assuming that every iteration of reading the sensor and sending the message takes roughly 300msec to complete, then the invocation callback is guaranteed to complete before the next period starts. </p><p>Graphically, this timeline looks like:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/image-20.png" class="kg-image" alt="The Waiting Loop"><figcaption>A timer-based periodic invocation timeline</figcaption></figure><p>But as we briefly touched on this in a <a href="https://havedatawilltrain.com/the-last-judgment/">previous post</a>, <strong>there is no guarantee of an IO operation duration. </strong>Let's say for example that because of a network glitch, the t+1 callback invocation takes more time to complete:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/image-8.png" class="kg-image" alt="The Waiting Loop"><figcaption>A timer-based periodic invocation timeline during a network glitch</figcaption></figure><p>The danger in this case is that at the cloud side we might end up with <strong>out-of-order messages </strong>that we'll then have to add special care to determine their actual order (we'll see next that we might have to do this either way). But most importantly, because we have parallel execution of the same code, we need to make sure that the code <strong>is thread safe, </strong>in other words, to ensure that we use <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.semaphore?view=netcore-3.1">semaphores</a> when we access shared (heap) memory.</p><p>An even more dangerous case leads to thread poll exhaustion. This can happen when instead of just a network glitch, we run into a network bottleneck that causes significant delay for all callback invocation completion:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/image-15.png" class="kg-image" alt="The Waiting Loop"><figcaption>A timer-based periodic invocation timeline during a network bottleneck</figcaption></figure><p> In this case, a catastrophic program failure is inevitable.</p><h2 id="task-timer">Task-timer</h2><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/daisyChain2.gif" class="kg-image" alt="The Waiting Loop"></figure><p>An alternative approach that mitigates these issues is to use to <a href="https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/chaining-tasks-by-using-continuation-tasks">chained tasks</a>. Although this approach might seem initially more complex, in reality is very straight forward. In C#, a <a href="https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/task-based-asynchronous-programming">Task </a>can have a continuation Task, which simply is another task that starts right after the former completes. By chaining together multiple callback invocation tasks and with adding the necessary <code>Task.Delay</code> between them, we can have the same periodical behavior as before:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/image-19.png" class="kg-image" alt="The Waiting Loop"><figcaption>A task-timer periodic invocation timeline</figcaption></figure><p>Going back to the previous network glitch scenario, the chained tasks will never produce any thread-unsafe or out-of-order messages cases, but rather just a period drift in just a single iteration:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/image-18.png" class="kg-image" alt="The Waiting Loop"><figcaption>A task-timer periodic invocation timeline during a network glitch.</figcaption></figure><p> The downside with this approach is that we lose our polling periodicity. Note that the delay in Callback #2 has shifted all the subsequent callbacks.</p><p>A task-timer implementation, as described above, is the code snippet below:</p><pre><code class="language-csharp">using System;
using System.Threading;
using System.Threading.Tasks;

public class TaskTimer
{
    CancellationTokenSource cancellationTokenSource;
    TimeSpan timerPeriod;
    Action onElapsedCallback;
    bool continueOnError;

    public TaskTimer(Action onElapsedCallback,
        TimeSpan timerPeriod,
        CancellationTokenSource cancellationTokenSource,
        bool continueOnError = true)
    {
        this.cancellationTokenSource = cancellationTokenSource;
        this.timerPeriod = timerPeriod;
        this.onElapsedCallback = onElapsedCallback;
        this.continueOnError = continueOnError;
    }

    public void Start()
    {
        Task elapsedTask = null;
        elapsedTask = new Task((x) =&gt;
        {
            Elapsed(elapsedTask, cancellationTokenSource);
        }, cancellationTokenSource.Token);

        HandleError(elapsedTask);

        elapsedTask.Start();
    }

    private void Elapsed(Task task, object objParam)
    {
        var start = DateTime.Now;
        var cancellationTokenSource = (CancellationTokenSource)objParam;
        if (cancellationTokenSource.Token.IsCancellationRequested)
        {
            Console.WriteLine("TaskTimer: A cancellation has been requested.");
            return;
        }

        onElapsedCallback();

        var delay = timerPeriod - (DateTime.Now - start);
        if (delay.Ticks &gt; 0)
        {
            task = Task.Delay(delay);
        }
        HandleError(task.ContinueWith(Elapsed, cancellationTokenSource));
    }

    private void HandleError(Task task)
    {
        task.ContinueWith((e) =&gt;
        {
            Console.WriteLine(
                $"Exception when running timer callback: {e.Exception}");
            if (!continueOnError)
                cancellationTokenSource.Cancel();
            else
                task.ContinueWith(Elapsed, cancellationTokenSource);
        }, TaskContinuationOptions.OnlyOnFaulted);
    }
}</code></pre><p><u>A few of notes about this <code>TaskTimer</code>: </u></p><p>The endless task-chaining is achieved by creating a <code>Task</code> with execution entry point in the <code>Elapsed</code> method (our callback) and by passing a reference of this task in the <code>Task</code> entry point arguments:</p><pre><code class="language-csharp">Task elapsedTask = null;
elapsedTask = new Task((x) =&gt;
{
	Elapsed(elapsedTask, cancellationTokenSource);
}, cancellationTokenSource.Token);</code></pre><p>Next, inside this <code>Elapsed</code> method, we continue the argument task with the same method:</p><pre><code class="language-csharp">task.ContinueWith(Elapsed, cancellationTokenSource)</code></pre><p>Between each continuation task, a delay might be added, based on the duration of the last iteration and the configured period:</p><pre><code class="language-csharp">var delay = timerPeriod - (DateTime.Now - start);
if (delay.Ticks &gt; 0)
{
    task = Task.Delay(delay);
}</code></pre><p>This implementation will break the task-chaining if the passed <code>CancellationToken</code> signals a cancellation:</p><pre><code class="language-csharp">if (cancellationTokenSource.Token.IsCancellationRequested)
{
    Console.WriteLine("TaskTimer: A cancellation has been requested.");
    return;
}</code></pre><p>Finally, the task-timer will trigger a cancellation signal if an exception is thrown by the callback, and the <code>continueOnError</code> is set to <code>false</code>:</p><pre><code class="language-csharp">private void HandleError(Task task)
{
    task.ContinueWith((e) =&gt;
    {
		Console.WriteLine(
            $"Exception when running timer callback: {e.Exception}");
        if (!continueOnError)
	        cancellationTokenSource.Cancel();
        else
    	    task.ContinueWith(Elapsed, cancellationTokenSource);
    }, TaskContinuationOptions.OnlyOnFaulted);
}</code></pre><p>Let's see now how our sample temperature module evolves using the this <code>TaskTimer</code>:</p><pre><code class="language-csharp">using System;
using System.Runtime.Loader;
using System.Threading;
using System.Threading.Tasks;

namespace Example4
{
    class Program
    {
        // This is the program entry point
        static async Task Main(string[] args)
        {
            // Create the cancellation token source
            var cancellationTokenSource = new CancellationTokenSource();
            AssemblyLoadContext.Default.Unloading +=
                (cts) =&gt; cancellationTokenSource.Cancel();

            Console.CancelKeyPress +=
                (sender, cts) =&gt;
                {
                    Console.WriteLine("Ctrl+C detected.");
                    cts.Cancel = true;
                    cancellationTokenSource.Cancel();
                };

            // Register the Reset command callback 
            await RegisterCommandCallbackAsync("Reset",
                OnReset,
                cancellationTokenSource.Token);

            // Create and start the TaskTimer
            TaskTimer taskTimer = new TaskTimer(
                EmitTelemetryMessage,
                TimeSpan.FromSeconds(1), cancellationTokenSource);

            // A non-blocking call to start the task-timer
            taskTimer.Start();

            // Wait until the app unloads or gets cancelled
            await WhenCancelled(cancellationTokenSource.Token);

            // Let the other threads drain
            Console.WriteLine("Waiting for 2 seconds..");
            await Task.Delay(TimeSpan.FromSeconds(2));

            Console.WriteLine("Exiting..");
        }

        public static Task WhenCancelled(CancellationToken cancellationToken)
        {
            var taskCompletionSource = new TaskCompletionSource&lt;bool&gt;();
            cancellationToken.Register(
                s =&gt; ((TaskCompletionSource&lt;bool&gt;)s).SetResult(true),
                taskCompletionSource);
            return taskCompletionSource.Task;
        }
        private static async Task RegisterCommandCallbackAsync(string command,
            Action callback,
            CancellationToken cancellationToken)
        {
            // Perform the command registration
            // Code omitted
            return;
        }

        // A method exposed for RPC
        static void OnReset()
        {
            // Perform a temperature sensor reset
            // Code omitted
        }

        // Emit telemetry message
        static void EmitTelemetryMessage()
        {
            Console.WriteLine($"Sending telemetry message..");
        }
    }
}
</code></pre><p>Arguably, this version is more readable and at the same time, we've avoided all aforementioned pitfalls. Running this version now produces a similar output as before:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/task-timer.gif" class="kg-image" alt="The Waiting Loop"></figure><p>So far, we've been using the <code>Console.WriteLine</code> function to print messages and we've avoided reading any application configuration. In the <a href="https://havedatawilltrain.com/the-service-room/">next post</a>, we'll examine the best approaches on the topic of the configuration.</p>]]></content:encoded></item><item><title><![CDATA[Restarted by request]]></title><description><![CDATA[This is the second post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge. This post deals with the topic of application restarting.]]></description><link>https://havedatawilltrain.com/restarted-by-request/</link><guid isPermaLink="false">5e86096c188f260074a3083d</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Sat, 04 Apr 2020 00:03:31 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/04/apollo.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/04/apollo.jpg" alt="Restarted by request"><p>In the <a href="https://havedatawilltrain.com/the-last-judgment/">previous post</a> we briefly touched on holding the main method from restarting, and as a trick, we used the <code>Console.ReadLine()</code> blocking call. But as we postulated, it's good to avoid any thread-blocking function calls. Furthermore, the process termination and recycling is a more complicated story, especially for code that is running on the edge, perhaps on a remote device with no keyboard, mouse or monitor to interact with. A better strategy in these cases is to control the process termination and use it as a recovery mechanism from unexpected situations, commonly called <strong>fatal exceptions. </strong></p><h2 id="application-termination-and-recycling">Application termination and recycling</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/04/onAndOff.gif" class="kg-image" alt="Restarted by request"><figcaption>The best troubleshooting strategy</figcaption></figure><h3 id="recycling">Recycling</h3><p>The Azure IoT Edge hosting mechanism can be configured to restart a stopped module through the <a href="https://docs.microsoft.com/en-us/azure/iot-edge/iot-edge-runtime "><strong>restartPolicy</strong></a><strong> </strong>configuration in the application manifest. The main point here is that the hosting runtime assumes that the application might crash and exit, and allowing the application to restart is a very appealing crash recovery mechanism that we should definitely leverage.</p><p>The <strong>restartPolicy</strong> configuration dictates how the IoT Edge agent restarts a module. Possible values include:</p><ul><li><code>never</code> â The IoT Edge agent never restarts the module.</li><li><code>on-failure</code> - If the module crashes, the IoT Edge agent restarts it. If the module shuts down cleanly, the IoT Edge agent doesn't restart it.</li><li><code>on-unhealthy</code> - If the module crashes or is considered unhealthy, the IoT Edge agent restarts it.</li><li><code>always</code> - If the module crashes, is considered unhealthy, or shuts down in any way, the IoT Edge agent restarts it.</li></ul><p>The product has other ways to remotely stop and start any module in an ad-hoc manner, so setting the <strong>restartPolicy</strong> to <code>always</code> is, generally speaking, a good strategy.</p><h3 id="cancellation">Cancellation</h3><p>In the second code sample of the <a href="https://havedatawilltrain.com/the-last-judgment/">previous post</a>, we saw how to use the async/await pattern to implement non-blocking code parallelism. But in that approach, there was no way to signal the application to exit gracefully, and this can become particularly challenging in highly parallel code. The .NET Core runtime provides a parallel operation cancellation mechanism through the <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.cancellationtokensource?view=netcore-3.1"><strong>CancellationTokenSource</strong></a><strong>. </strong></p><blockquote>When a fatal exception issue occurs, a <u>graceful exit is always preferred</u> versus an application crash, because this allows debugging information to be written in the application logs for post-mortem analysis.</blockquote><p>Now, let's see how our code evolves with the usage of a CancellationTokenSource:</p><pre><code class="language-csharp">using System;
using System.Runtime.Loader;
using System.Threading;
using System.Threading.Tasks;

namespace Example3
{
    class Program
    {
        // This is the program entry point
        static async Task Main(string[] args)
        {
            // Create the cancellation token source
            var cancellationTokenSource = new CancellationTokenSource();
            AssemblyLoadContext.Default.Unloading += 
                (cts) =&gt; cancellationTokenSource.Cancel();
            
            Console.CancelKeyPress +=
                (sender, cts) =&gt;
                {
                    Console.WriteLine("Ctrl+C detected.");
                    cts.Cancel = true;
                    cancellationTokenSource.Cancel();
                };

            // Register the Reset command callback 
            await RegisterCommandCallbackAsync("Reset", 
                OnReset, 
                cancellationTokenSource.Token);

            // A non-blocking telemetry emission invocation
            await EmitTelemetryMessagesAsync(cancellationTokenSource.Token);

            // Wait until the app unloads or gets cancelled
            await WhenCancelled(cancellationTokenSource.Token);

            // Let the other threads drain
            Console.WriteLine("Waiting for 2 seconds..");
            await Task.Delay(TimeSpan.FromSeconds(2));

            Console.WriteLine("Exiting..");
        }

        public static Task WhenCancelled(CancellationToken cancellationToken)
        {
            var taskCompletionSource = new TaskCompletionSource&lt;bool&gt;();
            cancellationToken.Register(
                s =&gt; ((TaskCompletionSource&lt;bool&gt;)s).SetResult(true), 
                taskCompletionSource);
            return taskCompletionSource.Task;
        }
        private static async Task RegisterCommandCallbackAsync(string command,
            Action callback,
            CancellationToken cancellationToken)
        {
            // Perform the command registration
            // Code omitted
            return;
        }

        // A method exposed for RPC
        static void OnReset()
        {
            // Perform a temperature sensor reset
            // Code omitted
        }

        // Emit telemetry messages
        static async Task EmitTelemetryMessagesAsync(
            CancellationToken cancellationToken)
        {
            while(true)
            {
                if (cancellationToken.IsCancellationRequested)
                {
                    Console.WriteLine($"Exiting telemetry pump..");
                    break;
                }
                Console.WriteLine($"Sending telemetry message..");
                await Task.Delay(TimeSpan.FromSeconds(1));
            }
        }
    }
}</code></pre><p>The cancellation token source allows us to signal a cancellation by invoking the <code>Cancel()</code> method, as we decided to do when the <code>AssemblyLoadContext.Default.Unloading</code> fires, an event that generally means your application is already exiting, or when the <code><a href="https://docs.microsoft.com/en-us/dotnet/api/system.console.cancelkeypress?view=netcore-3.1 ">Console.CancelKeyPress</a></code> event fires (Ctrl+C), useful for testing the cancellation mechanism in our development environment. A requested cancellation can be detected by the <code>cancellationToken.IsCancellationRequested</code> property, and then make sure we gracefully terminate any running parallel operation, similarly to what we did in the <code>EmitTelemetryMessagesAsync</code>. </p><blockquote>Now in the <code>EmitTelemetryMessagesAsync</code>we can loop forever and break based on the cancellation token signal. </blockquote><p>Finally, we can register to this cancellation event and when this event fires, let the Main method return by awaiting the <code>WhenCancelled</code> function. In other words, now we have an event driven mechanism to gracefully exit from all active threads of our program.</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2020/04/termination.gif" class="kg-image" alt="Restarted by request"></figure><p>The rules of thumb here are:</p><ol><li>Pass a reference of the CancellationToken to every async function, and to every the long-running synchronous. Use this token signal to gracefully return from these functions.</li><li>Pass a reference to the CancellationTokenSource to every function that performs critical operations that cannot recover from possible exceptions, e.g. initialization of used dependencies. Use the source to cancel the execution of the program.</li><li>Let the main function return when a cancellation is signaled. Allow some time for the other threads to complete their shutdown process.</li></ol><p>In the <a href="https://havedatawilltrain.com/the-waiting-loop/">next post</a> we will examine more elegant ways to implement telemetry pumps without the usage of while loops.</p>]]></content:encoded></item><item><title><![CDATA[The Last Judgment]]></title><description><![CDATA[This is the first post of a mini-series that aims to address the development experience and production readiness challenges in the space of IoT Edge, primarily under the lens of Azure IoT Edge.]]></description><link>https://havedatawilltrain.com/the-last-judgment/</link><guid isPermaLink="false">5e83c71e0b72be03aba4a5dd</guid><category><![CDATA[Azure IoT Edge]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Fri, 03 Apr 2020 23:44:19 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2020/03/TheLastJudgment.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2020/03/TheLastJudgment.jpg" alt="The Last Judgment"><p>Word is you like to live on the Edge, stranger.</p><p>Sometimes I like it too. I wish I didn't, but I do. I do it because that's where most of the interesting things happen, and for a good reason: <strong>zero latency</strong>. I wasn't always like that. I used to struggle with my equipment, didn't know where to start from, I was intimidated, I felt completely overwhelmed and powerless by this "technology". It took me some time to build up my skills and find my comfort zone, but to get there, the ride was rough. </p><p>For the past two years I've been working on various IoT Edge technologies. For the most part of it, my work was around the <strong><a href="https://azure.microsoft.com/en-us/services/iot-edge/">Azure IoT Edge</a> </strong>technology stack. Through this work, I came up with some ground rules that I personally think are the <strong>minimum prerequisites </strong>for any IoT development environment, especially for developers who write hardware-specific code, and some <strong>design principles </strong>that over time I've found great value in.</p><p>In this mini-series posts, I'll try to demonstrate these tools and patterns in an incremental way, starting from a simple console app that will gradually evolve to a production-ready Azure IoT Edge application. </p><h2 id="azure-iot-edge-the-main-gist">Azure IoT Edge: the main gist</h2><p>All edge technologies' purpose is to help you achieve one thing: <strong>run your code on a remote (network) device</strong>. This boils down to two distinct capabilities:</p><ol><li><strong>Deploy </strong>and <strong>manage </strong>your code on a device.</li><li>Establish communication with the device.</li></ol><p>We just experienced the proliferation of containers and, as expected, containers are the main deployment mechanism of Azure IoT Edge too. In Azure IoT Edge, one can deploy an application by creating the <strong>application manifest</strong>: a file that holds the information of which containers compose your application, and how these containers should be instantiated.</p><h2 id="the-development-tools-landscape">The development tools landscape</h2><p>There are development tools that help you build your containers and compose this manifest. Unfortunately, these tools rely heavily on the solution file system structure to operate, and come with unintuitive commands that mostly confuse rather than help. These tools rely on a thick stack of dependencies, that makes them flaky and slow, and print cryptic error messages. Even if you manage to properly install them on your development machine and use them to successfully compose your first IoT Edge application, the next challenge is to figure out how to debug this application. In a constant output log searching, lengthy redeployments, and remote debugging tricks, the whole development experience is frustrating.</p><p>The problem lies in the containerized nature of the deployment mechanism, and in the fact that this deployment mechanism was never abstracted out from the development experience. In addition to that, the deployment manifest is not generated by user code, and as a consequence, no code validation checks can apply to it. This means for example that tools like compilers, linters etc. are useless. If you decide to rename a class, any decent IDE/editor is clever enough to propagate this rename effect to the entire solution. But because this technology-unique manifest is exposed to the user, the application often breaks. Furthermore, it's difficult to have environment solution variants (debug, release etc.), because the compiler directives do not apply inside the manifest, and the tooling approach is to have dedicated replicas per configuration, making a large size application maintenance very difficult. Â  </p><h2 id="an-incremental-approach">An incremental approach</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2020/03/giphy.gif" class="kg-image" alt="The Last Judgment"><figcaption>RPC happiness</figcaption></figure><p>In it's most fundamental form, an IoT Edge application performs two functions:</p><ol><li>Processes device sensor data and emits some <strong>telemetry.</strong></li><li>Perform some form of <strong>RPC </strong>(remote command invocation).</li></ol><p>The typical documentation example of Azure IoT Edge is a <strong>temperature sensor</strong>, that emits the device temperature (telemetry), and has a reset method (command). As of writing this article, the source code of this example is <a href="https://github.com/Azure/iotedge/blob/2554c01d618446ebd8bcc1266d428d027a3d27f1/edge-modules/SimulatedTemperatureSensor/src/Program.cs">here</a>.</p><p>A simple console app that demonstrates this simulated temperature example looks like this:</p><figure class="kg-card kg-code-card"><pre><code class="language-csharp">using System;
using System.Threading;

namespace Example1
{
    class Program
    {
        // This is the program entry point
        static void Main(string[] args)
        {
            // Register the Reset command callback 
            RegisterCommandCallback("Reset", OnReset);

            // A non-blocking telemetry emission invocation
            new Thread(EmitTelemetryMessages).Start();

            // Wait until the app unloads or gets cancelled
            Console.ReadLine();
        }

        private static void RegisterCommandCallback(string command,
            Action callback)
        {
            // Perform the command registration
            // Code omitted
            return;
        }

        // A method exposed for RPC
        static void OnReset()
        {
            // Perform a temperature sensor reset
            // Code omitted
            return;
        }

        // Emit 500 telemetry messages
        static void EmitTelemetryMessages()
        {
            for (int i = 1; i &lt;= 500; i++)
            {
                Console.WriteLine($"Sending telemetry message {i} ..");
                Thread.Sleep(1000);
            }
        }
    }
}
</code></pre><figcaption>A simple IoT Edge Temperature Sensor</figcaption></figure><p>Let's break down what happens here. This example code performs three things:</p><ol><li>Registers a command callback (the actual registration code is omitted for clarity)</li><li>Sends some messages in a second thread</li><li>Waits for the user to press enter to exit.</li></ol><p>The latter step is there to ensure that the program does not exit immediately, before the other thread has the chance to send any message. In practice though, in a typical IoT Edge scenario there is no user to press enter, there's not even a monitor screen to print these messages. We'll see later on what's the best pattern to deal with this issue.</p><p>As with most containerized applications, this is a command-line initiated app, a <strong>console app</strong>. Console apps come from a time when all applications were single threaded and there was no GUI to interact with. The operating system would load the application binary code into a memory block, and start a thread at the program entry point, the <strong>main</strong> function. When this function returned, the program would exit. </p><p>When multithreaded applications were eventually allowed by modern operating systems, programmers could manually create a new thread and start it at any function. This felt like running multiple applications, but sharing the same memory block. This capability allowed the creation of a new programming style, called <strong>multithreaded event-driven</strong> that was very useful in scenarios like computer networking or graphical user interfaces, or in general, when functions had to be executed in a non-predefined order and timing, but rather based on external events.</p><p>Fast forward a few decades, and the modern languages have made it easier to deal with multithreaded event driven programming, generally called asynchronous programming . Tons of literature has been written about this topic, but the fundamental idea is simple: writing code that can react to external events of undetermined timing and order. C# in particular has the <strong><a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/async">async</a>/<a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/operators/await">await</a> pattern</strong>, which is an elegant way to execute some code in parallel (code that runs in a different thread). </p><p>Using this pattern, the above example becomes:</p><pre><code class="language-csharp">using System;
using System.Threading.Tasks;

namespace Example2
{
    class Program
    {
        // This is the program entry point
        static async Task Main(string[] args)
        {
            // Register the Reset command callback 
            await RegisterCommandCallbackAsync("Reset", OnReset);

            // A non-blocking telemetry emission invocation
            await EmitTelemetryMessagesAsync();

            // Wait until the app unloads or gets cancelled
            Console.ReadLine();
        }

        private static async Task RegisterCommandCallbackAsync(string command,
            Action callback)
        {
            // Perform the command registration
            // Code omitted 
            return;
        }

        // A method exposed for RPC
        static void OnReset()
        {
            // Perform a temperature sensor reset
            // Code omitted
            return;
        }

        // Emit 500 telemetry messages
        static async Task EmitTelemetryMessagesAsync()
        {
            for (int i = 1; i &lt;= 500; i++)
            {
                Console.WriteLine($"Sending telemetry message {i} ..");
                await Task.Delay(TimeSpan.FromSeconds(1));
            }
        }
    }
}</code></pre><blockquote>Note that we had to refactor our main function signature to be async</blockquote><p>These two versions are very similar in functionality, but with a major difference: in the latter example, there is no code segment that runs for an extensive period, in other words, <u>no thread is blocked by waiting for something to complete</u>. Indeed, in the first example, the thread we created to run the <code>EmitTelemetryMessages</code> function would periodically wait, blocked for a second at the <code>Thread.Sleep(1000)</code>. Blocked in this context means that the thread, although running, is waiting for something else to continue. This is not too important for now, but in real production systems becomes very important and helps to avoid the <u><a href="https://docs.microsoft.com/en-us/dotnet/standard/threading/the-managed-thread-pool">thread pool </a>starvation issue</u>, aka, running out of threads. </p><p>The rule of thumb here is: <u>anything that might take a considerable amount of time to complete, has to be implemented in the async/await pattern</u>. The important word here is <strong>might</strong>: generally speaking, things that require IO, like reading a file from the disk, sending a message over the network etc. fall into this category. Practically anything that does not run only in the context of the CPU should be awaited, because of the uncertainty of the completion time of the required additional hardware resource. But even for code that runs solely in the boundaries of the CPU, if it could take more than a few milliseconds to run, it should be awaited.</p><p>In the <a href="https://havedatawilltrain.com/restarted-by-request/">next article </a>we will examine the best approach to keep the main function from returning.</p>]]></content:encoded></item><item><title><![CDATA[Stream of the Jest]]></title><description><![CDATA[Exploring an optimized streaming Object Detection application pipeline using the DeepStream SDK and SSD Inception V2 COCO on a Jetson device.]]></description><link>https://havedatawilltrain.com/stream-of-the-jest/</link><guid isPermaLink="false">5d9cdad332f8e9003c17823e</guid><category><![CDATA[Jetson TX2]]></category><category><![CDATA[Object Detection]]></category><category><![CDATA[TensorRT]]></category><category><![CDATA[ARM]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Fri, 11 Oct 2019 21:29:44 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2019/10/053747ada3375e440325c09210983c7c.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2019/10/053747ada3375e440325c09210983c7c.jpg" alt="Stream of the Jest"><p>In a <a href="https://havedatawilltrain.com/three-threads-to-perdido/">previous post </a>we explored a high performance implementation of a Python <strong>Object Detector </strong>based on the <strong>SSD Inception V2 COCO </strong>model running on an <strong>NVIDIA Jetson TX2</strong>. In this post we will explore how we can implement the same Object Detector using NVIDIA's <strong><a href="https://developer.nvidia.com/deepstream-sdk">DeepStream SDK</a>.</strong></p><p>Previously, in the process of increasing the observed detector Frames Per Second (FPS) we saw how we can optimize the model with TensorRT and at the same time replace the simple synchronous while-loop implementation to an asynchronous multi-threaded one.</p><p>We noticed the increased FPS and the introduced trade-offs: the increased inference latency and the increased CPU and GPU utilization. Reading the web camera input frame-by-frame and pushing the data to the GPU for inference can be very challenging.</p><h2 id="deepstream-object-detector-on-a-jetson-tx2">DeepStream Object Detector on a Jetson TX2</h2><p>The data generated by a web camera are streaming data. By definition, data streams are continuous sources of data, in other words, sources that you cannot pause in any way. One of the strategies in processing data streams is to record the data and run an offline processing pipeline. This is called batch processing.</p><p>In our case we are interested in minimizing the latency of inference. A more appropriate strategy then would be a real time stream processing pipeline.<strong> </strong>The <a href="https://developer.nvidia.com/deepstream-sdk"><strong>DeepStream SDK</strong></a><strong> </strong>offers different<strong> hardware accelerated</strong> <strong>plugins </strong>to compose different real time stream processing pipelines. </p><p>NVIDIA also offers <a href="https://ngc.nvidia.com/catalog/containers/nvidia:deepstream-l4t"><strong>pre-built containers</strong></a> for running a containerized DeepStream application. Unfortunately, at the time of this blog post, the containers had some missing dependencies. For this reason, this application is run directly on the TX2 device.</p><h3 id="deepstream-object-detector-application-setup">DeepStream Object Detector application setup</h3><p>To run a custom DeepSteam object detector pipeline with the SSD Inception V2 COCO model on a TX2, run the following commands. </p><blockquote>I'm using JetPack 4.2.1</blockquote><h3 id="step-1-get-the-model-"><strong>Step 1: Get the model. </strong></h3><p>This command will download and extract in <code>/temp</code> the same model we used <a href="https://havedatawilltrain.com/three-threads-to-perdido/">in the Python implementation.</a></p><pre><code class="language-bash">wget -qO- http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz | tar xvz -C /tmp</code></pre><h3 id="step-2-optimize-the-model-with-tensorrt">Step 2: Optimize the model with TensorRT</h3><p>This command will convert this downloaded frozen graph to a UFF MetaGraph model.</p><pre><code class="language-bash">python3 /usr/lib/python3.6/dist-packages/uff/bin/convert_to_uff.py \
  /tmp/ssd_inception_v2_coco_2017_11_17/frozen_inference_graph.pb -O NMS \
  -p /usr/src/tensorrt/samples/sampleUffSSD/config.py \
  -o /tmp/sample_ssd_relu6.uff</code></pre><p>The generated UFF file is here: <code>/tmp/sample_ssd_relu6.uff</code>.</p><h3 id="step-3-compile-the-custom-object-detector-application">Step 3: Compile the custom object detector application</h3><p>This will build the <code>nvdsinfer_custom_impl</code> sample that comes with the SDK.</p><pre><code class="language-bash">cd /opt/nvidia/deepstream/deepstream-4.0/sources/objectDetector_SSD
CUDA_VER=10.0 make -C nvdsinfer_custom_impl</code></pre><p>We need to copy the UFF MetaGraph along with the label names file inside this folder.</p><pre><code class="language-bash">cp /usr/src/tensorrt/data/ssd/ssd_coco_labels.txt .
cp /tmp/sample_ssd_relu6.uff .</code></pre><h3 id="step-4-edit-the-application-configuration-file-to-use-your-camera">Step 4: Edit the application configuration file to use your camera</h3><p>Located in the same directory, the file <code>deepstream_app_config_ssd.txt</code> contains information about the DeepStream pipeline components, including the input source. The original example has been configured to use a static file as source.</p><pre><code>[source0]
enable=1
#Type - 1=CameraV4L2 2=URI 3=MultiURI
type=3
num-sources=1
uri=file://../../samples/streams/sample_1080p_h264.mp4
gpu-id=0
cudadec-memtype=0</code></pre><p>If you want to use a USB camera, make a copy of this file and change the above section to:</p><pre><code>[source0]
enable=1
#Type - 1=CameraV4L2 2=URI 3=MultiURI
type=1
camera-width=1280
camera-height=720
camera-fps-n=30
camera-fps-d=1
camera-v4l2-dev-node=1</code></pre><p>Save this as <code>deepstream_app_config_ssd_USB.txt</code>.</p><p>TX2 comes with an on board CSI camera. If you want to use the embedded CSI camera change the source to:</p><pre><code>[source0]
enable=1
#Type - 1=CameraV4L2 2=URI 3=MultiURI 4=RTSP 5=CSI
type=5
camera-width=1280
camera-height=720
camera-fps-n=30
camera-fps-d=1</code></pre><p>Save this file as <code>deepstream_app_config_ssd_CSI.txt</code>.</p><blockquote>Both cameras are configured to run at <strong>30 FPS with 1280x720 </strong>resolution. </blockquote><h3 id="execute-the-application">Execute the application</h3><p>To execute the Object Detection application using the USB camera, run:</p><pre><code class="language-bash">deepstream-app -c deepstream_app_config_ssd_USB.txt
</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/10/USB.gif" class="kg-image" alt="Stream of the Jest"><figcaption>DeepStream detector @16 FPS with the USB Camera</figcaption></figure><p>The application will print the FPS in the terminal, it's <strong>~16 FPS. </strong>This result is very similar to the TensorRT Python <a href="https://havedatawilltrain.com/three-threads-to-perdido/">implementation</a> where we had achieved 15 FPS in a simple Python while loop. </p><p>So what's the fuzz about DeepStream?</p><p>In a closer look, we can tell there is a substantial difference. The <code>tegrastats</code> output shows an semi-utilized GPU (~50%) and an under utilized CPU (~25%).</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/10/image-3.png" class="kg-image" alt="Stream of the Jest"></figure><p>The USB camera throughput is the obvious bottleneck in this pipeline. The Jetson TX2 <a href="https://developer.nvidia.com/embedded/jetson-tx2-developer-kit">development kit </a>comes with an on board 5 MP Fixed Focus MIPI CSI Camera out of the box.</p><p>The Camera Serial Interface (CSI) is a specification of the Mobile Industry Processor Interface (MIPI) Alliance. It defines an interface between a camera and a host processor. This means that the CSI camera can move the data in the GPU faster than the USB port.</p><p>Let's try the CSI camera.</p><pre><code class="language-bash">deepstream-app -c deepstream_app_config_ssd_CSI.txt
</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/10/ezgif-1-17a272e47f88.gif" class="kg-image" alt="Stream of the Jest"><figcaption>DeepStream detector @24 FPS with the CSI Camera</figcaption></figure><p>The average performance now is <strong>~24 FPS. </strong>Note that the theoretical maximum we can get is 30 FPS, since this is the camera frame rate.</p><p>We can see an obvious increase of the system utilization:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/10/image-4.png" class="kg-image" alt="Stream of the Jest"></figure><p>Let's try running both applications side by side:</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/10/both-1.gif" class="kg-image" alt="Stream of the Jest"><figcaption>~12 FPS for each application</figcaption></figure><p>The GPU now is operating at full capacity.</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/10/image-5.png" class="kg-image" alt="Stream of the Jest"></figure><p>The observed frame rates are <strong>~12 FPS </strong>for each application. Apparently, the <strong>maximum capacity of this GPU is ~24 inferences per second</strong> for this setup.</p><blockquote><em>Note: NVIDIA advertises <a href="https://developer.nvidia.com/deepstream-sdk">t</a>hat a DeepStream ResNet-based object<br>detector application can handle<strong> concurrently 14 independent 1080p 30fps </strong>video streams on a TX2. Here we see that <strong>this is far from true</strong> when using an industry standard detection model like SSD Inception V2 COCO.</em></blockquote><p><strong>What have we achieved: </strong><u>We've explored an optimized streaming Object Detection application pipeline using the DeepStream SDK and we've achieved the maximum detection throughput possible, as defined by the device's hardware limits.</u></p>]]></content:encoded></item><item><title><![CDATA[Three Threads to Perdido]]></title><description><![CDATA[This is the first part of a blog series that explores the topic of "High Throughput Object Detection" on the Edge.]]></description><link>https://havedatawilltrain.com/three-threads-to-perdido/</link><guid isPermaLink="false">5d321251435c041126c989a3</guid><category><![CDATA[TensorFlow]]></category><category><![CDATA[Object Detection]]></category><category><![CDATA[TensorRT]]></category><category><![CDATA[Jetson Nano]]></category><category><![CDATA[Jetson TX2]]></category><category><![CDATA[Docker]]></category><category><![CDATA[ARM]]></category><category><![CDATA[Containers]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Fri, 04 Oct 2019 18:56:00 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2019/10/cowboys-2277376-2.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2019/10/cowboys-2277376-2.jpg" alt="Three Threads to Perdido"><p>Welcome stranger, I've been expecting you.</p><p>I know what brought you here, it's despair. I know what is out there, Â I've seen it, and it's not pretty. Bad designs, broken code samples, no container definitions, missing dependency libraries, poor performance, you name it. </p><p>I was recently exploring ways to do<strong> real time object detection </strong>on my <strong>Nvidia Jetson TX2. </strong>The <em>real time </em>term here simply means, low latency and high throughput. It's a very loosely defined term, but it's used here in contrast to the store-and-process pattern, where storage is used as an interim stage.</p><hr><h2 id="high-performance-objection-detection-on-a-jetson-tx2">High Performance Objection Detection on a Jetson TX2</h2><h3 id="starting-simple">Starting simple</h3><p>We'll explore a simple program that detects human faces using the camera input and renders the camera input with the bounding boxes. This one is based on the<strong> <a href="https://docs.opencv.org/trunk/db/d28/tutorial_cascade_classifier.html">Haar Cascades</a></strong><a href="https://docs.opencv.org/trunk/db/d28/tutorial_cascade_classifier.html"> </a>and is one of the simplest ways to get started with Object Detection on the Edge. There is no Jetson platform dependency for this code, only on <strong>OpenCV</strong>.</p><blockquote><em>I'm using a remote development setup to do all of my coding that uses containers. This way you can experiment with all the code samples yourself without having to setup any runtime dependencies on your device.</em><br><br><a href="https://havedatawilltrain.com/got-nano-will-code/"><strong>Here </strong></a>is how I setup my device and my <a href="https://havedatawilltrain.com/drama-of-entropy/"><strong>remote development environment</strong></a> with VSCode.</blockquote><p>Start by cloning the <a href="https://github.com/paloukari/jetson-detectors">example code</a>. After cloning, you need to build and run the container that we'll be using to run our code.</p><!--kg-card-begin: markdown--><h3 id="clonetheexamplerepo">Clone the example repo</h3>
<pre><code>https://github.com/paloukari/jetson-detectors
cd jetson-detectors
</code></pre>
<h3 id="tobuildandrunthedevelopmentcontainer">To build and run the development container</h3>
<pre><code>sudo docker build . -f ./docker/Dockerfile.cpu -t object-detection-cpu
sudo docker run --rm --runtime nvidia --privileged -ti -e DISPLAY=$DISPLAY -v &quot;$PWD&quot;:/src -p 32001:22 object-detection-cpu
</code></pre>
<!--kg-card-end: markdown--><p>The <code>--privileged</code> is required for accessing all the devices. Alternatively you can use the <code>--device /dev/video0</code>. </p><p><a href="https://github.com/paloukari/jetson-detectors/blob/master/src/cpudetector.py">Here's the code we'll be running.</a> Simple open the <code>cpudetector.py</code> file in VSCode and hit F5 or just run: <code>python3 src/cpudetector.py</code>. In both cases you'll need to setup the X forwarding. See the <a href="https://havedatawilltrain.com/got-nano-will-code/">Step 2: X forwarding</a> on how to do this.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/10/cpu-2.gif" class="kg-image" alt="Three Threads to Perdido"><figcaption>~23 FPS with OpenCV</figcaption></figure><p><strong>We get about 23 FPS</strong>. Use the <code>tegrastats</code> to see what's happening in the GPU:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/10/image.png" class="kg-image" alt="Three Threads to Perdido"></figure><p>We're interested in the <code>GR3D_FREQ</code> values. It's clear that this code runs only on the device CPUs with more than 75% utilization per core, and with <strong>0% GPU utilization</strong>.</p><h3 id="next-up-we-use-go-deep">Next up, we use go Deep</h3><p>Haar Cascades is good, but how about detecting more things at once? In this case, we need to use Deep Neural Networks. We will need to use another container from now on to run the following code. </p><h3 id="to-build-and-run-the-gpu-accelerated-container">To build and run the GPU accelerated container</h3><pre><code>sudo docker build . -f ./docker/Dockerfile.gpu -t object-detection-gpu
sudo docker run --rm --runtime nvidia --privileged -ti -e DISPLAY=$DISPLAY -v "$PWD":/src -p 32001:22 object-detection-gpu
</code></pre><blockquote>WARNING: This build takes a few hours to complete on a TX2. The main reason is because we build the Protobuf library to increase to models loading performance. To reduce this the build time, you can <a href="https://github.com/NVIDIA/nvidia-docker/wiki/NVIDIA-Container-Runtime-on-Jetson#building-jetson-containers-on-an-x86-workstation-using-qemu">build the same container on a X64 workstation</a>.</blockquote><p>In the first attempt, we'll be using the official <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">TensorFlow pre-trained networks</a>. The code we'll be running is <a href="https://github.com/paloukari/jetson-detectors/blob/master/src/cpudetector.py">here</a>.</p><p>When you run <code>python3 src/gpudetector.py --model-name ssd_inception_v2_coco</code> , the code will try to download the specified model inside the <code>/models</code> folder, and start the object detection in a very similar fashion as we did before. The <code>--model-name</code> default value is <code>ssd_inception_v2_coco</code>, so you can omit it.</p><p>This model has been trained to detect 90 classes (you can see the details in the downloaded <code>pipeline.config</code> file). Our performance plummeted to <strong>~8 FPS.</strong></p><p>Run <code>python3 src/gpudetector.py</code></p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/10/gpu.gif" class="kg-image" alt="Three Threads to Perdido"><figcaption>~8 FPS with a the TensorFlow SSD Inception V2 COCO model</figcaption></figure><p>What happened? We've started running the inference in the GPU which for a single inference round trip now takes more time. Also, we move now a lot of data from the camera to RAM and from there to the GPU. This has an obvious performance penalty. </p><p>What we can do is start with optimizing the inference. We'll use the TensorRT optimization to speedup the inference. Run the same file as before, but now with the <code>--trt-optimize</code> flag. This flag will convert the specified TensorFlow mode to a TensorRT and save if to a local file for the next time.</p><p>Run <code>python3 gpudetector.py --trt-optimize</code>:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/10/ezgif-5-2f354c50d6b6.gif" class="kg-image" alt="Three Threads to Perdido"><figcaption>~15 FPS with TensorRT optimization&nbsp;</figcaption></figure><p>Better, but still far from perfect. The way we can tell is by looking at the GPU utilization in the background, it drops periodically to 0%. This happens because the code is being executed sequentially. In other words, for each frame we have to wait to get the bits from the camera, create an in memory copy, push it to the GPU, perform the inference, and render the original frame with the scoring results.</p><p>We can break down this sequential execution to an asynchronous parallel version. We can have a dedicated thread for reading the data from the camera, one for running inference in the GPU and one for rendering the results.</p><p>To test this version, run Â <code>python3 gpudetectorasync.py --trt-optimize</code></p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/10/gpurtasync.gif" class="kg-image" alt="Three Threads to Perdido"><figcaption>~40 FPS with async TensorRT</figcaption></figure><p>By parallelizing expensive calculations, we've achieved a better performance compared to the OpenCV first example. The trade off now is that we've introduced a slight delay between the current frame and the corresponding inference result. To be more precise here, because the inference now is running on an independent thread, the observed FPS do not match with the number of inferences per second.</p><p><strong>What we have achieved:</strong> <u>We've explored different ways of improving the performance of the typical pedagogic object detection while-loop.</u></p><p>Next,<a href="https://havedatawilltrain.com/stream-of-the-jest/"> in this post </a>we'll explore how we can improve even more our detector, by using the <a href="https://developer.nvidia.com/deepstream-sdk">DeepStream SDK</a>.</p>]]></content:encoded></item><item><title><![CDATA[Drama of entropy]]></title><description><![CDATA[Remote development using Docker Containers on a Jetson Device]]></description><link>https://havedatawilltrain.com/drama-of-entropy/</link><guid isPermaLink="false">5d8aad58bea92c00581d20fc</guid><category><![CDATA[Jetson Nano]]></category><category><![CDATA[Jetson TX2]]></category><category><![CDATA[Remote Debugging]]></category><category><![CDATA[VSCode]]></category><category><![CDATA[ARM]]></category><category><![CDATA[Docker]]></category><category><![CDATA[Containers]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Mon, 30 Sep 2019 20:17:07 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2019/10/Electrical-poles.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2019/10/Electrical-poles.jpg" alt="Drama of entropy"><p>I used to mess up my development environment over time by installing all the different experimentation dependencies. This is why I decided to switch to Docker containers.</p><p>The <strong>Jetson Nano </strong>default image comes with Docker runtime pre-installed. To package your app and avoid polluting your device OS with various dependencies, you can use Docker containers as development environments.</p><p>In fact, using a container as a development environment is a very similar to using directly a Jetson device for remote development. <a href="https://havedatawilltrain.com/got-nano-will-code/">Here's my post</a> on how to do the latter.</p><hr><h2 id="remote-debugging-inside-a-container-running-on-a-jetson-device">Remote Debugging inside a Container running on a Jetson Device</h2><p></p><p>The <strong><a href="https://github.com/NVIDIA/nvidia-docker/wiki/NVIDIA-Container-Runtime-on-Jetson">NVIDIA Container Runtime on Jetson</a> </strong>repo<strong> </strong>has great information on how to use GPU accelerated containers in both the Jetson family, and an X64 workstation.</p><p>Once you choose what's your base container, you'll need to setup a few more things. </p><p>You can either clone <strong><a href="https://github.com/paloukari/jetson-detectors">this repo</a></strong> that contains all the below code, or start from scratch. The assumed file structure of all the following code is:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/10/image-2.png" class="kg-image" alt="Drama of entropy"></figure><blockquote><strong>/keys: </strong>Here's where I keep my public ssh key.<br><strong>/.vscode:</strong> Here's where I keep my debugging configuration.<br><strong>/docker: </strong>Inside the <strong>docker </strong>folder I put the container definitions.<br><strong>/src: </strong>Here's the application source code.</blockquote><h3 id="-keys">/keys</h3><p>You will need to setup a passwordless ssh between your host's VSCode and the container. To do this, you'll need to copy your ssh public key in the container's <code>authorized_keys</code> file. To get your public ssh key, run:<code>cat ~/.ssh/id_rsa.pub</code>. Copy the key value in the <code>id_rsa.pub</code> key file that's inside the /keys folder.</p><blockquote>My host is a Windows 10 machine and I generally make sure that my Windows and WSL keys are the same. To do this, I've copied my keys from <code>~/.ssh/</code> to <code>/mnt/c/users/[YOUR USERNAME]/.ssh</code>/. This way I get a convenience security symmetry.</blockquote><h3 id="-vscode">/.vscode</h3><p>Here's the my <code>launch.json</code> and how to setup an X Server for forwarding any GUI running on the container to your host (<a href="https://havedatawilltrain.com/got-nano-will-code/">here's</a> more information how to set this up)</p><!--kg-card-begin: markdown--><pre><code>{    
    &quot;version&quot;: &quot;0.2.0&quot;,
    &quot;configurations&quot;: [
        {
            &quot;name&quot;: &quot;Python: Current File&quot;,
            &quot;type&quot;: &quot;python&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;program&quot;: &quot;${file}&quot;,
            &quot;console&quot;: &quot;integratedTerminal&quot;, 
            &quot;env&quot;:
            {
            &quot;DISPLAY&quot;: &quot;10.135.62.79:0.0&quot; 
            }
        }
    ]
}
</code></pre>
<!--kg-card-end: markdown--><blockquote>Replace the IP with your host's IP. I'm using the <strong>X410 X Server</strong> on Windows 10.</blockquote><h3 id="-docker">/docker</h3><p>In this example, I've started from a bare minimum, the<strong> l4t OS</strong>. This dockerfile is self explanatory. </p><!--kg-card-begin: markdown--><pre><code>FROM nvcr.io/nvidia/l4t-base:r32.2

ENV DEBIAN_FRONTEND=noninteractive

# Install Python3, Git and OpenCV
RUN apt-get update &amp;&amp; apt-get --yes install openssh-server python3-dev python3-pip python3-opencv git
RUN pip3 install --upgrade pip

RUN pip3 install click

ENV LC_ALL C.UTF-8
ENV LANG C.UTF-8

# Set the WORKDIR
WORKDIR /src

ENTRYPOINT service ssh restart &amp;&amp; bash

# Install the ssh public key - Remove this in a production deployment
COPY ./keys/id_rsa.pub /tmp/tmp.pub
RUN mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; cat /tmp/tmp.pub &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; chmod 600 ~/.ssh/authorized_keys &amp;&amp; rm -f /tmp/tmp.pub

</code></pre>
<!--kg-card-end: markdown--><h3 id="-src">/src</h3><p>This is where I put all the application code. You can test that the X forwarding works by opening running the <code>xtest.py</code>. You'll have to install the <code>eog</code> application in the container first by running <code>apt-get install eog</code> in a new VSCode terminal.</p><p>Here's the <code>xtest.py</code> code:</p><!--kg-card-begin: markdown--><pre><code>import subprocess
subprocess.run([&quot;eog&quot;])
</code></pre>
<!--kg-card-end: markdown--><h2 id="wiring-everything-up">Wiring everything up</h2><h3 id="on-your-jetson-device-run-">On your Jetson device, run:</h3><!--kg-card-begin: markdown--><pre><code># Clone the example repo
git clone https://github.com/paloukari/jetson-detectors
cd jetson-remote-development

# Build the dev container
sudo docker build . -f ./docker/Dockerfile.cpu -t object-detection-cpu

# Run the container
sudo docker run --rm --runtime nvidia --privileged -ti -e DISPLAY=$DISPLAY -v &quot;$PWD&quot;:/src -p 32001:22 object-detection-cpu
</code></pre>
<!--kg-card-end: markdown--><p>In your host's VSCode, add this information in the Remote-SSH configuration file:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/09/image-6.png" class="kg-image" alt="Drama of entropy"></figure><!--kg-card-begin: markdown--><pre><code>Host Nano
    User spyros
    HostName spyros-nano2
    IdentityFile ~/.ssh/id_rsa

Host NanoContainer
    User root
    HostName spyros-nano2
    IdentityFile ~/.ssh/id_rsa
    Port 32001

</code></pre>
<!--kg-card-end: markdown--><p>Now, you should be able to connect to the NanoContainer Remote SSH host. Last step is to install the Python VSCode extension on the remote host. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/09/image-8.png" class="kg-image" alt="Drama of entropy"><figcaption>The VSCode extensions need to be installed in both machines in a Remote-SSH session</figcaption></figure><p>Open the <code>xtest.py</code> and fit F5. </p><blockquote>You need to install the eog app in the container.</blockquote><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/10/ezgif-5-44d36401c343.gif" class="kg-image" alt="Drama of entropy"></figure><p><strong>What we achieved: </strong><u>We can now do remote development from a Windows host to a container running on a Jetson Nano, using VSCode.</u></p>]]></content:encoded></item><item><title><![CDATA[Got Nano, Wanna Code]]></title><description><![CDATA[Learn how to setup a remote development environment using VSCode from a Windows machine on a ARM device]]></description><link>https://havedatawilltrain.com/got-nano-will-code/</link><guid isPermaLink="false">5d7bf22d3694ea005ad2a5f8</guid><category><![CDATA[Jetson Nano]]></category><category><![CDATA[Remote Debugging]]></category><category><![CDATA[VSCode]]></category><category><![CDATA[ARM]]></category><dc:creator><![CDATA[Spyros Garyfallos]]></dc:creator><pubDate>Wed, 25 Sep 2019 20:39:41 GMT</pubDate><media:content url="https://havedatawilltrain.com/content/images/2019/09/Jetson-Nano_3QTR-Front_Left_trimmed-1.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://havedatawilltrain.com/content/images/2019/09/Jetson-Nano_3QTR-Front_Left_trimmed-1.jpg" alt="Got Nano, Wanna Code"><p>So, you just got your Jetson Nano and you're wondering how to get started? In this blog post you'll learn how to setup a remote development environment from your Windows 10 machine to a Jetson device.</p><h2 id="device-setup">Device Setup</h2><p>First, let's start with the device initial setup. To prepare my device, I followed the official <a href="https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#intro">getting started guide </a>from Nvidia. I used a <a href="https://www.amazon.com/SanDisk-128GB-Extreme-microSD-Adapter/dp/B07FCMKK5X/ref=asc_df_B07FCMKK5X/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=309776868400&amp;hvpos=1o1&amp;hvnetw=g&amp;hvrand=8725959158767136122&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1027744&amp;hvtargid=pla-588455240877&amp;psc=1">128 GB microSD</a> and a <a href="https://www.amazon.com/5V-4000mA-switching-power-supply/dp/B01LY5TG5Y">power adapter</a> to power up my device, along with the <a href="https://www.jetsonhacks.com/2019/04/10/jetson-nano-use-more-power/">required jumper</a>. I connected a Dell P2415Q monitor using an HDMI cable and my USB receiver for my Logitech Triathlon keyboard and mouse. My development laptop is a Windows 10 machine.</p><h2 id="desktop-sharing">Desktop Sharing </h2><p>The desktop sharing app is broken. Follow <a href="https://blog.hackster.io/getting-started-with-the-nvidia-jetson-nano-developer-kit-43aa7c298797">this</a> article to fix it. You can also find instructions there on how to use Microsoft's Remote Desktop.</p><h2 id="development-environment">Development Environment</h2><p>The latest trend of development experience in the software development industry is developing using <strong>CLIs </strong>and <strong>code editors</strong>. I generally enjoy having all moving parts together when I'm coding, or at least in proximity.</p><p><strong>Visual Studio Code</strong> succeeded in combining together a cross-platform code editor, community driven plugins and decent UI/UX for development. But what I really like with Visual Studio Code is the recent <strong><a href="https://code.visualstudio.com/docs/remote/remote-overview">Remote Development</a> </strong>capability that allows you to keep a local UI/UX experience, while working on a remote host or container.</p><p>The other thing I like having in my development environment is <strong>idempotency</strong>: not having to deal with the dependencies of the host. <strong>Containers </strong>allow me to have multiple dependency configurations on the same host, and moreover, to share code between different hosts. For this reason, in every code sample I present in this blog, I make sure to include the corresponding container.</p><h3 id="step-1-remote-development-on-a-jetson-nano">Step 1: Remote Development on a Jetson Nano</h3><p>Because the ARM64 architecture is not officially supported yet, to install<strong> Visual Studio Code</strong> on your <strong>Jetson Nano</strong>, for now you'll have to use the <a href="https://code.headmelted.com/">community binaries</a>.</p><p><strong>Installing Visual Studio Code on a Jetson Nano</strong></p><pre><code class="language-Bash"># Start an elevated session
sudo -s

# Install the community repo key
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 0CC3FD642696BFC8

# Run the installation script
. &lt;( wget -O - https://code.headmelted.com/installers/apt.sh )
</code></pre><p>If all goes well, you should get this output:</p><pre><code class="language-Bash">Installation complete!

You can start code at any time by calling "code-oss" within a terminal.

A shortcut should also now be available in your desktop menus (depending on your distribution).</code></pre><p>Next, you'll need to install the <strong><a href="https://code.visualstudio.com/insiders/">Visual Studio Code Insiders</a> on your host </strong>and install the <strong><a href="https://code.visualstudio.com/docs/remote/remote-overview">Remote Development</a> </strong>extension.</p><p>As a final step, you'll need to setup a passwordless SSH between your host and the Nano. To do this, you'll need to create an SSH public-private key pair and configure your device to trust your public key.</p><p>To setup your local SSH key in Windows run:</p><pre><code class="language-Powershell">Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0
ssh-keygen -t rsa -b 4096 
</code></pre><p>The keys will be created here: %USERPROFILE%\.ssh</p><p>To copy your public key to the device:</p><pre><code class="language-CMD">SET REMOTEHOST=user@device
scp %USERPROFILE%\.ssh\id_rsa.pub %REMOTEHOST%:~/tmp.pub
ssh %REMOTEHOST% "mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; cat ~/tmp.pub &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; chmod 600 ~/.ssh/authorized_keys &amp;&amp; rm -f ~/tmp.pub"</code></pre><!--kg-card-begin: markdown--><blockquote>
<p>You'll need to replace the value <strong>user@device</strong></p>
</blockquote>
<!--kg-card-end: markdown--><p>In you host VSCode, hit F1 and type <em>Remote-SSH: Open Configuration File..</em></p><p>Add your configuration:</p><pre><code class="language-Remote-SSH config">Host Nano
    User user
    HostName device
    IdentityFile ~/.ssh/id_rsa</code></pre><!--kg-card-begin: markdown--><blockquote>
<p>Replace the values <strong>user</strong> and <strong>device</strong></p>
</blockquote>
<!--kg-card-end: markdown--><p>Connect to your Nano clicking the low left corner green icon:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/09/image-1.png" class="kg-image" alt="Got Nano, Wanna Code"></figure><p>Congrats! Once connected, you can open a remote folder and open remote terminals directly in VSCode.</p><h3 id="step-2-x-forwarding">Step 2: X forwarding</h3><p>What about applications that have a GUI? No worries, you can setup an X forwarding from Nano to your host. To do this, I'm using the <a href="https://token2shell.com/x410/"><strong>X410 server</strong></a> for Windows. After installing and running the server, make sure you allow public access.</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/09/image-2.png" class="kg-image" alt="Got Nano, Wanna Code"></figure><p>All is left to do is to configure the X Forwarding on your Nano device.</p><p>Open a terminal in VSCode (<strong>Ctrl+Shift+`</strong> on Windows) and run:</p><pre><code class="language-Remote-SSH config">export DISPLAY=10.135.62.79:0.0</code></pre><!--kg-card-begin: markdown--><blockquote>
<p>Make sure you replace the above IP with your host IP</p>
</blockquote>
<!--kg-card-end: markdown--><p> To verify everything works, from the terminal run:</p><pre><code class="language-Remote-SSH config">eog</code></pre><p>If all goes well, you should see this window:</p><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com/content/images/2019/09/image-3.png" class="kg-image" alt="Got Nano, Wanna Code"></figure><p>To automatically set the remote variable when debugging your app, you can modify your<strong> launch.json </strong>and set the variable there:</p><pre><code class="language-launch.json">{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal", 
            "env":
            {
            "DISPLAY": "10.135.62.79:0.0" 
            }
        }
    ]
}</code></pre><p>To test all this, create a new python file containing the following code:</p><pre><code class="language-test.py">import subprocess
subprocess.run(["eog"])</code></pre><p>Now you can hit <strong>F5 </strong>and you'll get the same development experience, as with your local host, but<strong> running on a remote ARM machine!</strong></p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com/content/images/2019/09/ezgif-5-44d36401c343.gif" class="kg-image" alt="Got Nano, Wanna Code"><figcaption>Starting a remote debugging session on Jetson Nano</figcaption></figure><p><strong>What we have achieved: </strong><u>We can now do remote development from a Windows host to a Jetson Nano, using VSCode.</u></p><p>Next, we'll setup the same remote environment, <a href="https://havedatawilltrain.com/drama-of-entropy/">but on a Docker container running on the Jetson device</a>.</p>]]></content:encoded></item></channel></rss>