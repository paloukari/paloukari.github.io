<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Three Threads to Perdido</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css?v=004e71a0fd" />

    <link rel="shortcut icon" href="/favicon.png" type="image/png" />
    <link rel="canonical" href="https://havedatawilltrain.com//three-threads-to-perdido/" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="https://havedatawilltrain.com//three-threads-to-perdido/amp/" />
    
    <meta property="og:site_name" content="HAVE DATA - WILL TRAIN" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Three Threads to Perdido" />
    <meta property="og:description" content="This is the first part of a blog series that explores the topic of &quot;High Throughput Object Detection&quot; on the Edge." />
    <meta property="og:url" content="https://havedatawilltrain.com//three-threads-to-perdido/" />
    <meta property="og:image" content="https://havedatawilltrain.com//content/images/2019/10/cowboys_twitter-1.jpg" />
    <meta property="article:published_time" content="2019-10-04T18:56:00.000Z" />
    <meta property="article:modified_time" content="2019-10-10T15:01:48.000Z" />
    <meta property="article:tag" content="TensorFlow" />
    <meta property="article:tag" content="Object Detection" />
    <meta property="article:tag" content="TensorRT" />
    <meta property="article:tag" content="Jetson Nano" />
    <meta property="article:tag" content="Jetson TX2" />
    <meta property="article:tag" content="Docker" />
    <meta property="article:tag" content="ARM" />
    <meta property="article:tag" content="Containers" />
    
    <meta property="article:publisher" content="https://www.facebook.com/spyros.garyfallos" />
    <meta property="article:author" content="https://www.facebook.com/spyros.garyfallos" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Three Threads to Perdido" />
    <meta name="twitter:description" content="This is the first part of a blog series that explores the topic of &quot;High Throughput Object Detection&quot; on the Edge." />
    <meta name="twitter:url" content="https://havedatawilltrain.com//three-threads-to-perdido/" />
    <meta name="twitter:image" content="https://havedatawilltrain.com//content/images/2019/10/cowboys-2277376.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Spyros Garyfallos" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="TensorFlow, Object Detection, TensorRT, Jetson Nano, Jetson TX2, Docker, ARM, Containers" />
    <meta name="twitter:site" content="@SpyrosCarnation" />
    <meta name="twitter:creator" content="@SpyrosCarnation" />
    <meta property="og:image:width" content="800" />
    <meta property="og:image:height" content="428" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "HAVE DATA - WILL TRAIN",
        "logo": "https://havedatawilltrain.com//content/images/2019/07/Logo2.png"
    },
    "author": {
        "@type": "Person",
        "name": "Spyros Garyfallos",
        "image": {
            "@type": "ImageObject",
            "url": "https://havedatawilltrain.com//content/images/2019/09/Capture.PNG",
            "width": 375,
            "height": 439
        },
        "url": "https://havedatawilltrain.com//author/spyros/",
        "sameAs": [
            "https://www.facebook.com/spyros.garyfallos",
            "https://twitter.com/SpyrosCarnation"
        ]
    },
    "headline": "Three Threads to Perdido",
    "url": "https://havedatawilltrain.com//three-threads-to-perdido/",
    "datePublished": "2019-10-04T18:56:00.000Z",
    "dateModified": "2019-10-10T15:01:48.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://havedatawilltrain.com//content/images/2019/10/cowboys_twitter-1.jpg",
        "width": 800,
        "height": 428
    },
    "keywords": "TensorFlow, Object Detection, TensorRT, Jetson Nano, Jetson TX2, Docker, ARM, Containers",
    "description": "This is the first part of a blog series that explores the topic of &quot;High Throughput Object Detection&quot; on the Edge.",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://havedatawilltrain.com//"
    }
}
    </script>

    <meta name="generator" content="Ghost 2.31" />
    <link rel="alternate" type="application/rss+xml" title="HAVE DATA - WILL TRAIN" href="https://havedatawilltrain.com//rss/" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-148729349-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-148729349-1');
</script>

</head>
<body class="post-template tag-tensorflow tag-object-detection tag-tensorrt tag-jetson-nano tag-jetson-tx2 tag-docker tag-arm tag-containers">

    <div class="site-wrapper">

        

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
                <a class="site-nav-logo" href="https://havedatawilltrain.com/"><img src="/content/images/2019/07/Logo2.png" alt="HAVE DATA - WILL TRAIN" /></a>
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="https://havedatawilltrain.com//">Home</a></li>
    <li class="nav-author" role="menuitem"><a href="https://havedatawilltrain.com//author/spyros/">Author</a></li>
</ul>

    </div>
    <div class="site-nav-right">
        <div class="social-links">
                <a class="social-link social-link-fb" href="https://www.linkedin.com/in/spirosgarifallos/" title="Linkedin" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px"
width="26" height="26"
viewBox="0 0 192 192"
style=" fill:#000000;"><g fill="none" fill-rule="nonzero" stroke="none" stroke-width="1" stroke-linecap="butt" stroke-linejoin="miter" stroke-miterlimit="10" stroke-dasharray="" stroke-dashoffset="0" font-family="none" font-weight="none" font-size="none" text-anchor="none" style="mix-blend-mode: normal"><path d="M0,192v-192h192v192z" fill="none"></path><g fill="#ffffff"><g id="surface1"><path d="M156,0h-120c-19.875,0 -36,16.125 -36,36v120c0,19.875 16.125,36 36,36h120c19.875,0 36,-16.125 36,-36v-120c0,-19.875 -16.125,-36 -36,-36zM59.36539,162.98077h-29.82693l-0.17307,-89.30769h29.82692zM43.70192,61.99038h-0.17308c-9.75,0 -16.03846,-6.72115 -16.03846,-15.08653c0,-8.56731 6.49039,-15.0577 16.41347,-15.0577c9.92308,0 16.00961,6.49038 16.21153,15.0577c0,8.36538 -6.31731,15.08653 -16.41346,15.08653zM162.77885,162.98077h-30.08654v-48.51923c0,-11.74039 -3.11538,-19.73077 -13.61538,-19.73077c-8.01923,0 -12.34615,5.39423 -14.42308,10.61538c-0.77885,1.875 -0.98077,4.44231 -0.98077,7.06731v50.56731h-30.23077l-0.17308,-89.30769h30.23077l0.17308,12.60577c3.86538,-5.97116 10.29808,-14.42308 25.70192,-14.42308c19.09616,0 33.37501,12.46154 33.37501,39.25961v51.86539z"></path></g></g></g></svg></a>
                <a class="social-link social-link-tw" href="https://twitter.com/SpyrosCarnation" title="Twitter" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
        </div>
            <a class="rss-button" href="https://feedly.com/i/subscription/feed/https://havedatawilltrain.com//rss/" title="RSS" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
</a>
    </div>
</nav>
    </div>
</header>


<main id="site-main" class="site-main outer">
    <div class="inner">

        <article class="post-full post tag-tensorflow tag-object-detection tag-tensorrt tag-jetson-nano tag-jetson-tx2 tag-docker tag-arm tag-containers ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="2019-10-04">4 October 2019</time>
                        <span class="date-divider">/</span> <a href="/tag/tensorflow/">TensorFlow</a>
                </section>
                <h1 class="post-full-title">Three Threads to Perdido</h1>
            </header>

            <figure class="post-full-image">
                <img
                    srcset="/content/images/size/w300/2019/10/cowboys_twitter-1.jpg 300w,
                            /content/images/size/w600/2019/10/cowboys_twitter-1.jpg 600w,
                            /content/images/size/w1000/2019/10/cowboys_twitter-1.jpg 1000w,
                            /content/images/size/w2000/2019/10/cowboys_twitter-1.jpg 2000w"
                    sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px"
                    src="/content/images/size/w2000/2019/10/cowboys_twitter-1.jpg"
                    alt="Three Threads to Perdido"
                />
            </figure>

            <section class="post-full-content">
                <div class="post-content">
                    <p>Welcome stranger, I've been expecting you.</p><p>I know what brought you here, it's despair. I know what is out there,  I've seen it, and it's not pretty. Bad designs, broken code samples, no container definitions, missing dependency libraries, poor performance, you name it. </p><p>I was recently exploring ways to do<strong> real time object detection </strong>on my <strong>Nvidia Jetson TX2. </strong>The <em>real time </em>term here simply means, low latency and high throughput. It's a very loosely defined term, but it's used here in contrast to the store-and-process pattern, where storage is used as an interim stage.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h2 id="high-performance-objection-detection-on-a-jetson-tx2">High Performance Objection Detection on a Jetson TX2</h2><h3 id="starting-simple">Starting simple</h3><p>We'll explore a simple program that detects human faces using the camera input and renders the camera input with the bounding boxes. This one is based on the<strong> <a href="https://docs.opencv.org/trunk/db/d28/tutorial_cascade_classifier.html">Haar Cascades</a></strong><a href="https://docs.opencv.org/trunk/db/d28/tutorial_cascade_classifier.html"> </a>and is one of the simplest ways to get started with Object Detection on the Edge. There is no Jetson platform dependency for this code, only on <strong>OpenCV</strong>.</p><blockquote><em>I'm using a remote development setup to do all of my coding that uses containers. This way you can experiment with all the code samples yourself without having to setup any runtime dependencies on your device.</em><br><br><a href="https://havedatawilltrain.com//got-nano-will-code/"><strong>Here </strong></a>is how I setup my device and my <a href="https://havedatawilltrain.com//drama-of-entropy/"><strong>remote development environment</strong></a> with VSCode.</blockquote><p>Start by cloning the <a href="https://github.com/paloukari/jetson-detectors">example code</a>. After cloning, you need to build and run the container that we'll be using to run our code.</p><!--kg-card-begin: markdown--><h3 id="clonetheexamplerepo">Clone the example repo</h3>
<pre><code>https://github.com/paloukari/jetson-detectors
cd jetson-detectors
</code></pre>
<h3 id="tobuildandrunthedevelopmentcontainer">To build and run the development container</h3>
<pre><code>sudo docker build . -f ./docker/Dockerfile.cpu -t object-detection-cpu
sudo docker run --rm --runtime nvidia --privileged -ti -e DISPLAY=$DISPLAY -v &quot;$PWD&quot;:/src -p 32001:22 object-detection-cpu
</code></pre>
<!--kg-card-end: markdown--><p>The <code>--privileged</code> is required for accessing all the devices. Alternatively you can use the <code>--device /dev/video0</code>. </p><p><a href="https://github.com/paloukari/jetson-detectors/blob/master/src/cpudetector.py">Here's the code we'll be running.</a> Simple open the <code>cpudetector.py</code> file in VSCode and hit F5 or just run: <code>python3 src/cpudetector.py</code>. In both cases you'll need to setup the X forwarding. See the <a href="https://havedatawilltrain.com//got-nano-will-code/">Step 2: X forwarding</a> on how to do this.</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com//content/images/2019/10/cpu-2.gif" class="kg-image"><figcaption>~23 FPS with OpenCV</figcaption></figure><!--kg-card-end: image--><p><strong>We get about 23 FPS</strong>. Use the <code>tegrastats</code> to see what's happening in the GPU:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://havedatawilltrain.com//content/images/2019/10/image.png" class="kg-image"></figure><!--kg-card-end: image--><p>We're interested in the <code>GR3D_FREQ</code> values. It's clear that this code runs only on the device CPUs with more than 75% utilization per core, and with <strong>0% GPU utilization</strong>.</p><h3 id="next-up-we-use-go-deep">Next up, we use go Deep</h3><p>Haar Cascades is good, but how about detecting more things at once? In this case, we need to use Deep Neural Networks. We will need to use another container from now on to run the following code. </p><h3 id="to-build-and-run-the-gpu-accelerated-container">To build and run the GPU accelerated container</h3><!--kg-card-begin: code--><pre><code>sudo docker build . -f ./docker/Dockerfile.gpu -t object-detection-gpu
sudo docker run --rm --runtime nvidia --privileged -ti -e DISPLAY=$DISPLAY -v "$PWD":/src -p 32001:22 object-detection-gpu
</code></pre><!--kg-card-end: code--><blockquote>WARNING: This build takes a few hours to complete on a TX2. The main reason is because we build the Protobuf library to increase to models loading performance. To reduce this the build time, you can <a href="https://github.com/NVIDIA/nvidia-docker/wiki/NVIDIA-Container-Runtime-on-Jetson#building-jetson-containers-on-an-x86-workstation-using-qemu">build the same container on a X64 workstation</a>.</blockquote><p>In the first attempt, we'll be using the official <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">TensorFlow pre-trained networks</a>. The code we'll be running is <a href="https://github.com/paloukari/jetson-detectors/blob/master/src/cpudetector.py">here</a>.</p><p>When you run <code>python3 src/gpudetector.py --model-name ssd_inception_v2_coco</code> , the code will try to download the specified model inside the <code>/models</code> folder, and start the object detection in a very similar fashion as we did before. The <code>--model-name</code> default value is <code>ssd_inception_v2_coco</code>, so you can omit it.</p><p>This model has been trained to detect 90 classes (you can see the details in the downloaded <code>pipeline.config</code> file). Our performance plummeted to <strong>~8 FPS.</strong></p><p>Run <code>python3 src/gpudetector.py</code></p><!--kg-card-begin: image--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com//content/images/2019/10/gpu.gif" class="kg-image"><figcaption>~8 FPS with a the TensorFlow SSD Inception V2 COCO model</figcaption></figure><!--kg-card-end: image--><p>What happened? We've started running the inference in the GPU which for a single inference round trip now takes more time. Also, we move now a lot of data from the camera to RAM and from there to the GPU. This has an obvious performance penalty. </p><p>What we can do is start with optimizing the inference. We'll use the TensorRT optimization to speedup the inference. Run the same file as before, but now with the <code>--trt-optimize</code> flag. This flag will convert the specified TensorFlow mode to a TensorRT and save if to a local file for the next time.</p><p>Run <code>python3 gpudetector.py --trt-optimize</code>:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com//content/images/2019/10/ezgif-5-2f354c50d6b6.gif" class="kg-image"><figcaption>~15 FPS with TensorRT optimization&nbsp;</figcaption></figure><!--kg-card-end: image--><p>Better, but still far from perfect. The way we can tell is by looking at the GPU utilization in the background, it drops periodically to 0%. This happens because the code is being executed sequentially. In other words, for each frame we have to wait to get the bits from the camera, create an in memory copy, push it to the GPU, perform the inference, and render the original frame with the scoring results.</p><p>We can break down this sequential execution to an asynchronous parallel version. We can have a dedicated thread for reading the data from the camera, one for running inference in the GPU and one for rendering the results.</p><p>To test this version, run  <code>python3 gpudetectorasync.py --trt-optimize</code></p><!--kg-card-begin: image--><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://havedatawilltrain.com//content/images/2019/10/gpurtasync.gif" class="kg-image"><figcaption>~40 FPS with async TensorRT</figcaption></figure><!--kg-card-end: image--><p>By parallelizing expensive calculations, we've achieved a better performance compared to the OpenCV first example. The trade off now is that we've introduced a slight delay between the current frame and the corresponding inference result. To be more precise here, because the inference now is running on an independent thread, the observed FPS do not match with the number of inferences per second.</p><p><strong>What we have achieved:</strong> <u>We've explored different ways of improving the performance of the typical pedagogic object detection while-loop.</u></p><p>In a future post we'll explore how we can improve even more our detector, by using the <a href="https://developer.nvidia.com/deepstream-sdk">DeepStream SDK</a>.</p>
                </div>
            </section>


            <footer class="post-full-footer">


                    
<section class="author-card">
        <img class="author-profile-image" src="/content/images/size/w100/2019/09/Capture.PNG" alt="Spyros Garyfallos" />
    <section class="author-card-content">
        <h4 class="author-card-name"><a href="/author/spyros/">Spyros Garyfallos</a></h4>
            <p>Read <a href="/author/spyros/">more posts</a> by this author.</p>
    </section>
</section>
<div class="post-full-footer-right">
    <a class="author-card-button" href="/author/spyros/">Read More</a>
</div>


            </footer>

            
            <section class="post-full-comments">
                <div id="disqus_thread"></div>
                <script>
                    var disqus_config = function () {
                        this.page.url = "https://havedatawilltrain.com//three-threads-to-perdido/";  
                        this.page.identifier = "ghost-5d321251435c041126c989a3"
                    };
                    (function() {
                    var d = document, s = d.createElement('script');
                    s.src = 'https://have-data-will-train.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })();
                </script>
            </section>
            

        </article>

    </div>
</main>

<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">


                <article class="post-card post tag-jetson-nano tag-jetson-tx2 tag-remote-debugging tag-vscode tag-arm tag-docker tag-containers ">

    <a class="post-card-image-link" href="/drama-of-entropy/">
        <img class="post-card-image"
            srcset="/content/images/size/w300/2019/09/Electrical-poles.jpg 300w,
                    /content/images/size/w600/2019/09/Electrical-poles.jpg 600w,
                    /content/images/size/w1000/2019/09/Electrical-poles.jpg 1000w,
                    /content/images/size/w2000/2019/09/Electrical-poles.jpg 2000w"
            sizes="(max-width: 1000px) 400px, 700px"
            src="/content/images/size/w600/2019/09/Electrical-poles.jpg"
            alt="Drama of entropy"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="/drama-of-entropy/">

            <header class="post-card-header">
                    <span class="post-card-tags">Jetson Nano</span>
                <h2 class="post-card-title">Drama of entropy</h2>
            </header>

            <section class="post-card-excerpt">
                <p>I used to mess up my development environment over time by installing all the different experimentation dependencies. To package your app and avoid polluting your device OS with various dependencies, you can use Docker containers as development environments.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Spyros Garyfallos
                    </div>

                        <a href="/author/spyros/" class="static-avatar">
                            <img class="author-profile-image" src="/content/images/size/w100/2019/09/Capture.PNG" alt="Spyros Garyfallos" />
                        </a>
                </li>
            </ul>

            <span class="reading-time">4 min read</span>

        </footer>

    </div>

</article>

        </div>
    </div>
</aside>

<div class="floating-header">
    <div class="floating-header-logo">
        <a href="https://havedatawilltrain.com/">
                <img src="/content/images/size/w30/2019/07/icon.png" alt="HAVE DATA - WILL TRAIN icon" />
            <span>HAVE DATA - WILL TRAIN</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Three Threads to Perdido</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Three%20Threads%20to%20Perdido&amp;url=https://havedatawilltrain.com//three-threads-to-perdido/"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://havedatawilltrain.com//three-threads-to-perdido/"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
        </a>
    </div>
    <progress id="reading-progress" class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>




        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://havedatawilltrain.com/">HAVE DATA - WILL TRAIN</a> &copy; 2019</section>
                <nav class="site-footer-nav">
                    <a href="https://havedatawilltrain.com/">Latest Posts</a>
                    <a href="https://www.linkedin.com/in/spirosgarifallos/" target="_blank" rel="noopener">LinkedIn</a>
                    <a href="https://twitter.com/SpyrosCarnation" target="_blank" rel="noopener">Twitter</a>
                </nav>
            </div>
        </footer>

    </div>


    <script>
        var images = document.querySelectorAll('.kg-gallery-image img');
        images.forEach(function (image) {
            var container = image.closest('.kg-gallery-image');
            var width = image.attributes.width.value;
            var height = image.attributes.height.value;
            var ratio = width / height;
            container.style.flex = ratio + ' 1 0%';
        })
    </script>


    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/built/jquery.fitvids.js?v=004e71a0fd"></script>


    <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('#reading-progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();

});
</script>


    

</body>
</html>
